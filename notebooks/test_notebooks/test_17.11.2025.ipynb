{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(current_dir,\"..\"))\n",
    "project_root = os.path.abspath(os.path.join(project_root,\"..\")) # one level more down\n",
    "paths_to_add = [project_root,\n",
    "                os.path.join(project_root,\"src\",\"init\")]\n",
    "for path in paths_to_add:\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "os.environ['ANTHROPIC_API_KEY'] = ANTHROPIC_API_KEY\n",
    "# connection to db\n",
    "connection_string = os.getenv('CONNECTION_STRING_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All terms in synonyms exist in key_terms\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import agent\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "graph = agent.graph\n",
    "\n",
    "orchestrator = agent.orchestrator\n",
    "run_control_flow = agent.run_control_flow\n",
    "generate_answer = agent.generate_answer\n",
    "create_sql_query_or_queries = agent.create_sql_query_or_queries\n",
    "extract_analytical_intent = agent.extract_analytical_intent\n",
    "\n",
    "# Import initialization components\n",
    "from src.init.initialization import (\n",
    "    llm, llm_fast, create_config, tracer,\n",
    "    objects_documentation, sql_dialect, connection_string\n",
    ")\n",
    "\n",
    "question = 'placeholder'\n",
    "test_state = {\n",
    "'objects_documentation':objects_documentation,\n",
    "'sql_dialect': sql_dialect,\n",
    "'messages_log':[],\n",
    "'intermediate_steps' : [],\n",
    "'analytical_intent': [],\n",
    "'current_question':question,\n",
    "'current_sql_queries': [],\n",
    "'generate_answer_details': {\n",
    "    'key_assumptions': [],\n",
    "    'agent_questions': [],\n",
    "    'ambiguity_explanation': ''\n",
    "},\n",
    "'llm_answer': AIMessage(content=''),\n",
    "'scenario': ''\n",
    ",'search_terms_output':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the conversation with the graph\n",
    "question = 'aum by practice segments'\n",
    "\n",
    "test_state['current_question'] = question\n",
    "vector_store = None  # reset vector store\n",
    "config, thread_id = create_config('Run Agent',True)\n",
    "\n",
    "result = graph.invoke(test_state, config = config)\n",
    "display = f'''Analytical intent: {result['analytical_intent']}\\n\\nSQL query: {result['current_sql_queries']}\\n\\nGenerate Answer Details: {result['generate_answer_details']}\\n\\nAnswer: {result['llm_answer'].content}'''\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['search_terms_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue the conversation with the graph (followup 1)\n",
    "question = 'can you say again which one is the best one? sorry i missed it'\n",
    "\n",
    "test_state['current_question'] = question\n",
    "vector_store = None  # reset vector store\n",
    "config, _ = create_config('Run Agent', False, thread_id) # (re-use same thread)\n",
    "result = graph.invoke(test_state, config)\n",
    "display = f'''Analytical intent: {result['analytical_intent']}\\n\\nSQL query: {result['current_sql_queries']}\\n\\nGenerate Answer Details: {result['generate_answer_details']}\\n\\nAnswer: {result['llm_answer']}'''\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "orchestrator = agent.orchestrator\n",
    "run_control_flow = agent.run_control_flow\n",
    "generate_answer = agent.generate_answer\n",
    "create_sql_query_or_queries = agent.create_sql_query_or_queries\n",
    "extract_analytical_intent = agent.extract_analytical_intent\n",
    "reset_state = agent.reset_state\n",
    "\n",
    "# Import initialization components\n",
    "from src.init.initialization import  llm, llm_fast, create_config, tracer, objects_documentation, sql_dialect, connection_string\n",
    "\n",
    "question = 'aum by practice segments'\n",
    "\n",
    "test_state = {\n",
    "'objects_documentation':objects_documentation,\n",
    "'sql_dialect': sql_dialect,\n",
    "'messages_log':[],\n",
    "'intermediate_steps' : [],\n",
    "'analytical_intent': [],\n",
    "'current_question':question,\n",
    "'current_sql_queries': [],\n",
    "'generate_answer_details': {\n",
    "    'key_assumptions': [],\n",
    "    'agent_questions': [],\n",
    "    'ambiguity_explanation': ''\n",
    "},\n",
    "'llm_answer': AIMessage(content=''),\n",
    "'scenario': ''\n",
    ",'search_terms_output':[]\n",
    "}\n",
    "\n",
    "#test_state = reset_state(test_state)\n",
    "#orchestrator(test_state)\n",
    "#test_state = run_control_flow(test_state) # extract_analytical_intent\n",
    "#test_state = run_control_flow(test_state) # create sql query + execute sql query\n",
    "#orchestrator(test_state)\n",
    "#test_state = run_control_flow(test_state) # generate answer + manage memory\n",
    "# test_state = generate_answer.invoke({'state':test_state})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run reset_state\n",
    "test_state = reset_state(test_state)\n",
    "print(test_state['objects_documentation']) # check objects_documentation\n",
    "print(test_state['scenario']) # scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "extract_analytical_intent\n"
     ]
    }
   ],
   "source": [
    "# run orchestrator\n",
    "orchestrator(test_state)\n",
    "print(test_state['analytical_intent']) # analytical intent\n",
    "print(test_state['scenario']) # scenario\n",
    "print(test_state['intermediate_steps'][-1].tool) # next action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run extract analytical intent\n",
    "test_state = run_control_flow(test_state)\n",
    "print(test_state['analytical_intent']) # analytical intent\n",
    "print(test_state['scenario']) # scenario\n",
    "print(test_state['intermediate_steps'][-1].tool) # next action\n",
    "print(test_state['search_terms_output'])\n",
    "print(test_state['generate_answer_details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run create sql query\n",
    "test_state = run_control_flow(test_state)\n",
    "print(test_state['analytical_intent']) # analytical intent\n",
    "print(test_state['current_sql_queries']) # scenario\n",
    "print(test_state['generate_answer_details']['key_assumptions'])\n",
    "print(test_state['intermediate_steps'][-1].tool) # next action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key_assumptions': []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent import extract_terms_used_in_intent, add_key_assumptions_from_analytical_intent\n",
    "\n",
    "analytical_intent = test_state['analytical_intent']\n",
    "search_terms_output = test_state['search_terms_output']\n",
    "# extract_terms_used_in_intent\n",
    "add_key_assumptions_from_analytical_intent(analytical_intent, search_terms_output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a0fce415d2e9e6477a25b7ed122e649823ddf5df417fe3f69c00ade6d8eb08b"
  },
  "kernelspec": {
   "display_name": "Python 3.13.5 ('.venv-py313': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
