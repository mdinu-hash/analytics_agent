{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add root to sys path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "root = os.path.abspath(os.path.join(current_dir,\"..\",\"..\"))\n",
    "if root not in sys.path:\n",
    "    sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['ANTHROPIC_API_KEY'] = ANTHROPIC_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import agent\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "graph = agent.graph\n",
    "create_config = agent.create_config\n",
    "objects_documentation = agent.objects_documentation\n",
    "database_content = agent.database_content\n",
    "sql_dialect = agent.sql_dialect\n",
    "orchestrator = agent.orchestrator\n",
    "run_control_flow = agent.run_control_flow\n",
    "generate_answer = agent.generate_answer\n",
    "create_sql_query_or_queries = agent.create_sql_query_or_queries\n",
    "extract_analytical_intent = agent.extract_analytical_intent\n",
    "\n",
    "# Import initialization components\n",
    "from src.init.initialization import (\n",
    "    llm, llm_fast, create_config, tracer,\n",
    "    objects_documentation, database_content, sql_dialect, connection_string\n",
    ")\n",
    "\n",
    "question = 'placeholder'\n",
    "test_state = {\n",
    "'objects_documentation':objects_documentation,\n",
    "'database_content':database_content,\n",
    "'sql_dialect': sql_dialect,\n",
    "'messages_log':[],\n",
    "'intermediate_steps' : [],\n",
    "'analytical_intent': [],\n",
    "'current_question':question,\n",
    "'current_sql_queries': [],\n",
    "'generate_answer_details': {},\n",
    "'llm_answer': AIMessage(content='')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Which firms make up the most revenue?' \n",
    "\n",
    "test_state['current_question'] = question\n",
    "vector_store = None  # reset vector store\n",
    "config, thread_id = create_config('Run Agent',True)\n",
    "#test_state = extract_analytical_intent.invoke({'state':test_state})\n",
    "result = graph.invoke(test_state, config = config)\n",
    "display = f'''Analytical intent: {result['analytical_intent']}\\n\\nSQL query: {result['current_sql_queries']}\\n\\nGenerate Answer Details: {result['generate_answer_details']}\\n\\nAnswer: {result['llm_answer'].content}'''\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'For Oak Wealth, what was their EOM asset value and payout?'\n",
    "\n",
    "test_state['current_question'] = question\n",
    "vector_store = None  # reset vector store\n",
    "config, thread_id = create_config('Run Agent',True)\n",
    "#test_state = extract_analytical_intent.invoke({'state':test_state})\n",
    "result = graph.invoke(test_state, config = config)\n",
    "display = f'''Analytical intent: {result['analytical_intent']}\\n\\nSQL query: {result['current_sql_queries']}\\n\\nGenerate Answer Details: {result['generate_answer_details']}\\n\\nAnswer: {result['llm_answer'].content}'''\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'For advisor ID 8, show their products usage status, total assets and payout.'\n",
    "\n",
    "test_state['current_question'] = question\n",
    "vector_store = None  # reset vector store\n",
    "config, thread_id = create_config('Run Agent',True)\n",
    "#test_state = extract_analytical_intent.invoke({'state':test_state})\n",
    "result = graph.invoke(test_state, config = config)\n",
    "display = f'''Analytical intent: {result['analytical_intent']}\\n\\nSQL query: {result['current_sql_queries']}\\n\\nGenerate Answer Details: {result['generate_answer_details']}\\n\\nAnswer: {result['llm_answer'].content}'''\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-questions Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the conversation with the graph\n",
    "question = 'Which household segment is responsible for most revenue?' \n",
    "\n",
    "test_state['current_question'] = question\n",
    "vector_store = None  # reset vector store\n",
    "config, thread_id = create_config('Run Agent',True)\n",
    "\n",
    "result = graph.invoke(test_state, config = config)\n",
    "display = f'''Analytical intent: {result['analytical_intent']}\\n\\nSQL query: {result['current_sql_queries']}\\n\\nGenerate Answer Details: {result['generate_answer_details']}\\n\\nAnswer: {result['llm_answer'].content}'''\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue the conversation with the graph (followup 1)\n",
    "question = 'Which segments have the most room to grow?'\n",
    "\n",
    "test_state['current_question'] = question\n",
    "vector_store = None  # reset vector store\n",
    "config, _ = create_config('generate_answer', False, thread_id) # (re-use same thread)\n",
    "result = graph.invoke(test_state, config)\n",
    "display = f'''Analytical intent: {result['analytical_intent']}\\n\\nSQL query: {result['current_sql_queries']}\\n\\nGenerate Answer Details: {result['generate_answer_details']}\\n\\nAnswer: {result['llm_answer']}'''\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue the conversation with the graph (followup 2)\n",
    "question = 'I would like to identify practice segments that make up a high revenue but they are a small % of firms as a number.'\n",
    "\n",
    "test_state['current_question'] = question\n",
    "vector_store = None  # reset vector store\n",
    "config, _ = create_config('generate_answer', False, thread_id) # (re-use same thread)\n",
    "result = graph.invoke(test_state, config)\n",
    "display = f'''Analytical intent: {result['analytical_intent']}\\n\\nSQL query: {result['current_sql_queries']}\\n\\nGenerate Answer Details: {result['generate_answer_details']}\\n\\nAnswer: {result['llm_answer']}'''\n",
    "print(display)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95f65b872249b8b9751ec454d9f1d56929740dd6969ecea16b02b402412196d8"
  },
  "kernelspec": {
   "display_name": "Python 3.13.5 ('.venv-py313': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
