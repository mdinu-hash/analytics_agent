{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add root to sys path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "root = os.path.abspath(os.path.join(current_dir,\"..\"))\n",
    "if root not in sys.path:\n",
    "    sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['ANTHROPIC_API_KEY'] = ANTHROPIC_API_KEY\n",
    "\n",
    "import agent\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "graph = agent.graph\n",
    "\n",
    "orchestrator = agent.orchestrator\n",
    "run_control_flow = agent.run_control_flow\n",
    "generate_answer = agent.generate_answer\n",
    "create_sql_query_or_queries = agent.create_sql_query_or_queries\n",
    "extract_analytical_intent = agent.extract_analytical_intent\n",
    "\n",
    "# Import initialization components\n",
    "from src.init.initialization import (\n",
    "    llm, llm_fast, create_config, tracer,\n",
    "    objects_documentation, sql_dialect, connection_string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Questions with Expected Outcomes\n",
    "eval_questions = [\n",
    "    {\n",
    "        'question': 'aum by practice segments',\n",
    "        'expected_outcome': 'Query for assets under management and not aggregate it over time.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'Payments associated with advisors from firm Cedar Capital LLC',\n",
    "        'expected_outcome': 'Enter disambiguation node. Payment can mean net revenue (Revenue retained by Capital Partners) or payout (Dollar amount paid to advisor). Ask user which one they prefer.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'net revenue associated with Cedar Capital advisors',\n",
    "        'expected_outcome': 'Filter for sum of net revenue for advisors belonging to the firm Cedar Capital LLC'\n",
    "    },\n",
    "    {\n",
    "        'question': 'distribution of advisor ID 8',\n",
    "        'expected_outcome': 'Enter disambiguation node. Distribution (advisor payout after tech fees are deducted) is not in tables. Offer net revenue (Revenue retained by Capital Partners) or payout (Dollar amount paid to advisor), ask which one user prefers.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'producing assets by practice segments',\n",
    "        'expected_outcome': 'Query for advisory assets. Say that advisory assets is Assets in Managed Portfolio and SMA business lines.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'liquid assets by practice segments',\n",
    "        'expected_outcome': 'Say it doesn\\'t have access to liquid assets (assets easily converted to cash) but here are the results for advisory assets (Assets in Managed Portfolio and SMA business lines).'\n",
    "    },\n",
    "    {\n",
    "        'question': 'For Oak Wealth, what was their EOM asset value and payout?',\n",
    "        'expected_outcome': 'Query for EOM assets and payout for Oak Wealth firm.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What is distinct count of active advisors?',\n",
    "        'expected_outcome': 'Query for distinct count of advisors with advisor_status = Active and to_date = 9999-12-31.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'List all advisors affiliated with firm Crescent Wealth LLC.',\n",
    "        'expected_outcome': 'Query for advisors belonging to firm Crescent Wealth LLC.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'Group advisors by tenure group. Compare average total assets, net revenue across these groups. Which group shows the highest revenue per advisor?',\n",
    "        'expected_outcome': 'Group by tenure, calculate avg assets and net revenue, identify highest revenue per advisor group.'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Running eval 1/10: aum by practice segments\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'objects_documentation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Reset test_state for each question\u001b[39;00m\n\u001b[32m     17\u001b[39m test_state = {\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mobjects_documentation\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mobjects_documentation\u001b[49m,\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msql_dialect\u001b[39m\u001b[33m'\u001b[39m: sql_dialect,\n\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmessages_log\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m     21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mintermediate_steps\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m     22\u001b[39m     \u001b[33m'\u001b[39m\u001b[33manalytical_intent\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcurrent_question\u001b[39m\u001b[33m'\u001b[39m: question,\n\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcurrent_sql_queries\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgenerate_answer_details\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     26\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mkey_assumptions\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m     27\u001b[39m         \u001b[33m'\u001b[39m\u001b[33magent_questions\u001b[39m\u001b[33m'\u001b[39m: [],\n\u001b[32m     28\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mambiguity_explanation\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     29\u001b[39m     },\n\u001b[32m     30\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mllm_answer\u001b[39m\u001b[33m'\u001b[39m: AIMessage(content=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     31\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mscenario\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     32\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msearch_terms_output\u001b[39m\u001b[33m'\u001b[39m: []\n\u001b[32m     33\u001b[39m }\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Create config with \"Run Evals\" prefix\u001b[39;00m\n\u001b[32m     36\u001b[39m config, thread_id = create_config(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRun Evals - Q\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'objects_documentation' is not defined"
     ]
    }
   ],
   "source": [
    "# Run Evaluations\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize results list\n",
    "eval_results = []\n",
    "\n",
    "# Run each evaluation question\n",
    "for i, eval_item in enumerate(eval_questions):\n",
    "    question = eval_item['question']\n",
    "    expected_outcome = eval_item['expected_outcome']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Running eval {i+1}/{len(eval_questions)}: {question}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Reset test_state for each question\n",
    "    test_state = {\n",
    "        'objects_documentation': objects_documentation,\n",
    "        'sql_dialect': sql_dialect,\n",
    "        'messages_log': [],\n",
    "        'intermediate_steps': [],\n",
    "        'analytical_intent': [],\n",
    "        'current_question': question,\n",
    "        'current_sql_queries': [],\n",
    "        'generate_answer_details': {\n",
    "            'key_assumptions': [],\n",
    "            'agent_questions': [],\n",
    "            'ambiguity_explanation': ''\n",
    "        },\n",
    "        'llm_answer': AIMessage(content=''),\n",
    "        'scenario': '',\n",
    "        'search_terms_output': []\n",
    "    }\n",
    "    \n",
    "    # Create config with \"Run Evals\" prefix\n",
    "    config, thread_id = create_config(f'Run Evals - Q{i+1}', True)\n",
    "    \n",
    "    try:\n",
    "        # Invoke graph\n",
    "        result = graph.invoke(test_state, config=config)\n",
    "        \n",
    "        # Extract relevant state details\n",
    "        eval_result = {\n",
    "            'eval_number': i + 1,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'question': question,\n",
    "            'expected_outcome': expected_outcome,\n",
    "            'scenario': result.get('scenario', ''),\n",
    "            'analytical_intent': result.get('analytical_intent', []),\n",
    "            'current_sql_queries': result.get('current_sql_queries', []),\n",
    "            'generate_answer_details': result.get('generate_answer_details', {}),\n",
    "            'agent_answer': result.get('llm_answer').content if result.get('llm_answer') else '',\n",
    "            'thread_id': thread_id,\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"✓ Completed - Scenario: {eval_result['scenario']}\")\n",
    "        print(f\"  Answer preview: {eval_result['agent_answer'][:100]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Capture errors\n",
    "        eval_result = {\n",
    "            'eval_number': i + 1,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'question': question,\n",
    "            'expected_outcome': expected_outcome,\n",
    "            'scenario': '',\n",
    "            'analytical_intent': [],\n",
    "            'current_sql_queries': [],\n",
    "            'generate_answer_details': {},\n",
    "            'agent_answer': '',\n",
    "            'thread_id': thread_id,\n",
    "            'status': 'error',\n",
    "            'error_message': str(e)\n",
    "        }\n",
    "        print(f\"✗ Error: {str(e)}\")\n",
    "    \n",
    "    eval_results.append(eval_result)\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ Evaluations complete!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Total questions: {len(eval_results)}\")\n",
    "print(f\"  Successful: {sum(1 for r in eval_results if r['status'] == 'success')}\")\n",
    "print(f\"  Errors: {sum(1 for r in eval_results if r['status'] == 'error')}\")\n",
    "print(f\"\\nScenario distribution:\")\n",
    "for scenario in ['A', 'B', 'C', 'D']:\n",
    "    count = sum(1 for r in eval_results if r.get('scenario') == scenario)\n",
    "    if count > 0:\n",
    "        print(f\"  Scenario {scenario}: {count}\")\n",
    "\n",
    "# eval_results is now available for further analysis in subsequent cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect individual eval results\n",
    "import json\n",
    "\n",
    "def display_eval(eval_number):\n",
    "    \"\"\"Display detailed results for a specific eval\"\"\"\n",
    "    result = eval_results[eval_number - 1]\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"EVAL #{result['eval_number']}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(f\"Question: {result['question']}\\n\")\n",
    "    print(f\"Expected Outcome: {result['expected_outcome']}\\n\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    print(f\"Scenario: {result['scenario']}\")\n",
    "    print(f\"Status: {result['status']}\")\n",
    "    \n",
    "    if result['status'] == 'error':\n",
    "        print(f\"\\nError: {result.get('error_message', 'Unknown error')}\")\n",
    "    else:\n",
    "        print(f\"\\nAnalytical Intent:\")\n",
    "        for intent in result['analytical_intent']:\n",
    "            print(f\"  - {intent}\")\n",
    "        \n",
    "        print(f\"\\nSQL Queries: {len(result['current_sql_queries'])} query(ies)\")\n",
    "        for i, query in enumerate(result['current_sql_queries'], 1):\n",
    "            print(f\"  Query {i}: {query.get('query', '')[:100]}...\")\n",
    "        \n",
    "        print(f\"\\nGenerate Answer Details:\")\n",
    "        print(f\"  Key Assumptions: {len(result['generate_answer_details'].get('key_assumptions', []))}\")\n",
    "        for assumption in result['generate_answer_details'].get('key_assumptions', []):\n",
    "            print(f\"    - {assumption}\")\n",
    "        print(f\"  Agent Questions: {result['generate_answer_details'].get('agent_questions', [])}\")\n",
    "        print(f\"  Ambiguity Explanation: {result['generate_answer_details'].get('ambiguity_explanation', '')}\")\n",
    "        \n",
    "        print(f\"\\nAgent Answer:\")\n",
    "        print(f\"  {result['agent_answer']}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "# Example usage: display_eval(1) to see results for first eval"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a0fce415d2e9e6477a25b7ed122e649823ddf5df417fe3f69c00ade6d8eb08b"
  },
  "kernelspec": {
   "display_name": "Python 3.13.5 ('.venv-py313': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
