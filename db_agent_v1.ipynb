{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a56df5",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc147a51",
   "metadata": {},
   "source": [
    "### Import feedbacks.db file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5b824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test access to db file: import db tables into data frames and select by the column names\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import uuid\n",
    "\n",
    "engine = create_engine('sqlite:///feedbacks_db.db')\n",
    "inspector = inspect(engine)\n",
    "\n",
    "df_company = pd.read_sql_query('SELECT company_name,annual_revenue_usd FROM company', engine)\n",
    "df_feedback = pd.read_sql_query('SELECT feedback_id,feedback_date,product_id,product_company_name,feedback_text,\"feedback_rating\" FROM feedback', engine)\n",
    "df_products = pd.read_sql_query('SELECT product_id,product_name,product_brand,product_manufacturer,product_company_name,product_price,product_average_rating FROM products', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4008f31",
   "metadata": {},
   "source": [
    "### Instantiate chat model (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de278ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain, langgraph, langchain_openai, langsmith\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "os.environ['LANGSMITH_API_KEY'] = LANGSMITH_API_KEY\n",
    "os.environ['LANGSMITH_TRACING'] = \"true\"\n",
    "os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "langsmith_project_name = \"db_agent_v1\"\n",
    "os.environ['LANGSMITH_PROJECT'] = langsmith_project_name\n",
    "\n",
    "# Set up LangSmith tracer manually\n",
    "tracer = LangChainTracer(project_name=langsmith_project_name)\n",
    "\n",
    "from langchain_openai import ChatOpenAI \n",
    "llm = ChatOpenAI(model='gpt-4.1',temperature=0) # Smart & expensive\n",
    "llm_fast = ChatOpenAI(model='gpt-4o',temperature=0) # Faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530fc53d",
   "metadata": {},
   "source": [
    "### Create config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b11c69a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_config(run_name: str, is_new_thread_id: bool = False, thread_id: str = None):\n",
    "    \"\"\"\n",
    "    Create a config dictionary for LCEL runnables.\n",
    "    Includes LangSmith run tracing and optional thread_id management.\n",
    "\n",
    "    Args:\n",
    "        run_name (str): Descriptive run name shown in LangSmith.\n",
    "        is_new_thread_id (bool): Whether to generate a new thread_id.\n",
    "        thread_id (str): Optionally provide an existing thread_id to reuse.\n",
    "\n",
    "    Returns:\n",
    "        dict: Config dictionary with callbacks, run_name, and thread_id.\n",
    "\n",
    "    Use it like so (example): \n",
    "        config, thread_id = create_config('create_sql_query_or_queries', True) (start a new thread)\n",
    "        config, _ = create_config('generate_answer', False, thread_id) (re-use same thread)\n",
    "    \"\"\"\n",
    "\n",
    "    time_now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    full_run_name = f\"{run_name} {time_now}\"\n",
    "    if is_new_thread_id or not thread_id:\n",
    "        thread_id = str(uuid.uuid4())\n",
    "\n",
    "    config={'callbacks': [tracer],\n",
    "            'run_name': full_run_name,\n",
    "            'configurable' : { 'thread_id':thread_id }\n",
    "            }\n",
    "\n",
    "    return config,thread_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebaf8f1",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7348f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = None\n",
    "\n",
    "objects_documentation = '''Table company: List of public companies. Granularity is company-name. Column (prefixed with table name):\n",
    "     company.company-name: the name of the public company.\n",
    "     company.annual_revenue_usd: revenue in last 12 months ($).\n",
    "\n",
    "     Table feedback: Feedbacks given by clients to products. Granularity is feedback. Key is feedback_id. Columns (prefixed with table name):\n",
    "     feedback.feedback_id: id of the feedback.\n",
    "     feedback.feedback_date: date of feedback.\n",
    "     feedback.product_id: id of the product the feedback was given for.\n",
    "     feedback.product_company_name: company owning the product.\n",
    "     feedback.feedback_text: the text of the feedback.\n",
    "     feedback.feedback_rating: rating of the feedback from 1 to 5, 5 being the highest score.\n",
    "\n",
    "     Table products: Shows product metadata. Granularity is product. Key is product_id. Columns (prefixed with table name):\n",
    "     products.product_id: id of the product.\n",
    "     products.product_name: name of the product.\n",
    "     products.product_brand: the brand under which the product was presented.\n",
    "     products.product_manufacturer: product manufacturer.\n",
    "     products.product_company_name: company owning the product.\n",
    "     products.product_price: price of the product at crawling time.\n",
    "     products.product_average_rating: average ratings across all feedbacks for the product, at crawling time.\n",
    "\n",
    "     Table company -> column company_name relates to table feedback -> column product_company_name\n",
    "     Table products -> column product_company_name relates to table feedback -> column product_company-name\n",
    "     Table feedback -> column product_id relates to table products -> column product_id'''\n",
    "\n",
    "database_content = '''Feedback dates between 18 November 2002 and 12 september 2023. \n",
    "These feedbacks are given to amazon website by purchasers of various products. \n",
    "There are 12 companies selling these products, some of them being Apple, Samsung, Sony, Nike, Adidas, Microsoft or Verizon. \n",
    "The feedback ratings range from 1 the lowest to 5 the highest.\n",
    "Other main data points are product price, product name, or company last annual revenue. \n",
    "Less important attributes of the dataset are product brands or manufacturers, I say less important because there are many facturers or brands to give as examples. \n",
    "\n",
    "Feedback table has 413k rows. Products table has 8145 rows.\n",
    "'''\n",
    "\n",
    "sql_dialect = 'SQLite'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977899ef",
   "metadata": {},
   "source": [
    "### Define state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d272a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the state of the graph, which includes user's question, AI's answer, query that has been created and its result;\n",
    "from typing_extensions import TypedDict, Annotated, Literal, Union\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Sequence\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, RemoveMessage\n",
    "from langchain_core.agents import AgentAction\n",
    "import operator\n",
    "\n",
    "class State(TypedDict):\n",
    " objects_documentation: str\n",
    " database_content: str\n",
    " sql_dialect: str\n",
    " messages_log: Sequence[BaseMessage]\n",
    " intermediate_steps: list[AgentAction]\n",
    " analytical_intent: list[str]\n",
    " current_question: str\n",
    " current_sql_queries: list[dict]\n",
    " generate_answer_details: dict\n",
    " llm_answer: BaseMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496f5c4",
   "metadata": {},
   "source": [
    "## Extract analytical intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4788c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "def extract_msg_content_from_history(messages_log:list):\n",
    " ''' from a list of base messages, extract just the content '''\n",
    " content = []\n",
    " for msg in messages_log:\n",
    "     content.append(msg.content)\n",
    " return \"\\n\".join(content)\n",
    "\n",
    "class ClearOrAmbiguous(TypedDict):\n",
    "  ''' conclusion about the analytical intent extraction process '''\n",
    "  analytical_intent_clearness: Annotated[Literal[\"Analytical Intent Extracted\", \"Analytical Intent Ambiguous\"],\"conclusion about the analytical intent extraction process\"] \n",
    "\n",
    "class AnalyticalIntents(TypedDict):\n",
    "  ''' list of analytical intents '''\n",
    "  analytical_intent: Annotated[Union[list[str], None] ,\"natural language descriptions to capture the analytical intents\"]                                      \n",
    "\n",
    "@tool\n",
    "def extract_analytical_intent(state:State):\n",
    "  ''' generates a natural language description to capture the analytical intent and refine the user ask ''' \n",
    "  \n",
    "  sys_prompt_clear_or_ambiguous = \"\"\"Decide whether the user question is clear or ambigous based on this specific database schema:\n",
    "  {objects_documentation}.\n",
    "\n",
    "  Conversation history:\n",
    "  \"{messages_log}\".\n",
    "\n",
    "  User question:\n",
    "  \"{question}\".\n",
    "\n",
    "  *** The question is clear if ***\n",
    "  - It has a single, obvious analytical approach in terms of grouping, filtering, aggregations using available columns and relationships or past conversations.\n",
    "\n",
    "  - The column and metric naming in the schema clearly points to one dominant method of interpretation. \n",
    "    Example: \"what is the top client?\" is clear in a database schema that contains just 1 single metric that can answer the question (ex: sales_amount). \n",
    "  \n",
    "  - The question is exploratory or open-ended.\n",
    "    Example: \"What can you tell me about the dataset?\".\n",
    "\n",
    "  - It refers to the evolution of metrics over time (ex last 12 months sales).  \n",
    "\n",
    "  - You can deduct the analytical intent from the conversation history.\n",
    "  \n",
    "  *** The question is ambigous if ***\n",
    "  - The question could be answered from different analytical intents that use different metrics, grouping, filtering or aggregations.\n",
    "    Example: Use pre-aggregated metrics vs metrics computed from aggregations across detailed tables.\n",
    "\n",
    "  - It can be answered by different metrics or metric definitions.\n",
    "    Example: \"What is the top client?\" is ambigous in a database schema that contains multiple metrics that can answer the question (highest value of sales / highest number of sales). \n",
    "\n",
    "  Response format:\n",
    "  If clear -> \"Analytical Intent Extracted\".\n",
    "  If ambigous -> \"Analytical Intent Ambiguous\". \n",
    "  \"\"\"\n",
    "\n",
    "  sys_prompt_clear = \"\"\"Refine technically the user ask for a sql developer with access to the following database schema:\n",
    "  {objects_documentation}.\n",
    "\n",
    "  Summary of database content:\n",
    "  {database_content}.\n",
    "\n",
    "  Conversation history:\n",
    "  \"{messages_log}\".\n",
    "\n",
    "  Last user prompt:\n",
    "  \"{question}\".  \n",
    "\n",
    "Important considerations about creating analytical intents:\n",
    "    - The analytical intent will be used to create a single sql query.\n",
    "    - Write it in 1 sentence.\n",
    "    - Mention just the column names, tables names, grouping levels, aggregation functions (preffered if it doesn't restrict insights) and filters from the database schema.  \n",
    "    - If the user ask is exploratory (ex: \"What can you tell me about the dataset?\"), create 3-5 analytical intents. \n",
    "    - If the user ask is non-exploratory, create only one analytical intent.\n",
    "    - If the user asks for statistical analysis between variables (ex correlation) do not compute the statistical metrics, instead just show a simple side by side or group summary.\n",
    "\n",
    "  Important considerations about time based analysis:\n",
    "    - Use explicit date filters instead of relative expressions like “last 12 months”. Derive actual date ranges from the feedback date ranges described in database_content. \n",
    "    - Group the specified period in time-based groups (monthly, quarterly) and compare first with last group.\n",
    "\n",
    "  Important considerations about complex, multi-steps analytical intents:  \n",
    "  - An analytical query is multi-step if it requires sequential data gathering and statistical analysis, \n",
    "    where each search builds upon previous results to examine relationships, correlations, or comparative patterns between variables.  \n",
    "  - Break it down into sequential steps where each represents a distinct analytical intent:\n",
    "    Template: \"Step 1: <analytical intent 1>. Step 2: <analytical intent 2>. Step 3: <analytical intent 3>\"  \n",
    "    \"\"\"\n",
    "\n",
    "  sys_prompt_ambiguous = \"\"\"\n",
    "  Conversation history:\n",
    "  \"{messages_log}\".\n",
    "\n",
    "  Last user prompt:\n",
    "  \"{question}\". \n",
    "\n",
    "  The last user question is ambiguous from the analytical point of view, because it can be answered using different analytical intents that can be interpreted in multiple ways leading to different results.\n",
    "  \n",
    "  That is, there are different sql queries with different metadata (object names/filters/aggregations) that can answer the question.\n",
    "\n",
    "  Your task is to create all analytical intents that can possibly answer the user question using the following database schema:  \n",
    "  {objects_documentation}.             \n",
    "\n",
    "  Important considerations about creating analytical intents:\n",
    "      - Each analytical intent is for creating one single sql query.\n",
    "      - Write each analytical intent using 1 sentence.\n",
    "      - Mention specific column names, tables names as well as aggregation functions (preffered if it doesn't restrict insights) and filters from the database schema.  \n",
    "      - Mention only the useful info for creating sql queries.   \n",
    "      - Do not include redundant intents. \n",
    "\n",
    "  Create one analytical intent for every possible pattern from the checklist that can answer the user quesion:  \n",
    "\n",
    "  ** Pattern Checklist **\n",
    "      1. filter on same table.\n",
    "        Example: select product_id from product table where avg_sales = 5.\n",
    "\n",
    "      2. Retrieve records from table A based on filter criteria from table B (assuming tables A and B are related).\n",
    "        Example: count of product_id from product table where unit_sale from sales table = 12.\n",
    "\n",
    "      3. filter records from table A based on calculated aggregations (AVG, SUM, COUNT) from table B (assuming tables A and B are related).\n",
    "        Example: count products from products table where AVG(amount) from sales table grouped by product > 100.     \n",
    "  \"\"\"\n",
    "  sys_prompt_notes = \"\"\"\n",
    "  Conversation history:\n",
    "  \"{messages_log}\".\n",
    "\n",
    "  Last user prompt:\n",
    "  \"{question}\". \n",
    "  \n",
    "  The last user question is ambiguous from the analytical point of view, because it can be answered using different analytical intents that can be interpreted in multiple ways leading to different results.\n",
    "  That is, there are different sql queries with different metadata (object names/filters/aggregations) that can answer the question.\n",
    "  The sql queries can only pull data from this database schema:\n",
    "  {objects_documentation}.\n",
    "\n",
    "  The different analytical intents that make the question ambiguous are the following:\n",
    "  {analytical_intents}.         \n",
    "  \n",
    "  Your task is to create an explanation of what makes the question unclear and show the alternatives.\n",
    "  Just acknowledge why is ambiguous and mention the alternatives, nothing more.\n",
    "  Be short, concise, explain in simple, non-technical language.\n",
    "  \"\"\"  \n",
    "\n",
    "  prompt_clear_or_ambiguous = ChatPromptTemplate.from_messages([('system', sys_prompt_clear_or_ambiguous)])\n",
    "  chain_1= prompt_clear_or_ambiguous | llm.with_structured_output(ClearOrAmbiguous)  \n",
    "\n",
    "  prompt_clear = ChatPromptTemplate.from_messages([('system', sys_prompt_clear)])\n",
    "  chain_2= prompt_clear | llm.with_structured_output(AnalyticalIntents)\n",
    "\n",
    "  prompt_ambiguous = ChatPromptTemplate.from_messages([('system', sys_prompt_ambiguous)])\n",
    "  chain_3= prompt_ambiguous | llm.with_structured_output(AnalyticalIntents)\n",
    "\n",
    "  prompt_notes = ChatPromptTemplate.from_messages([('system', sys_prompt_notes)])\n",
    "  chain_4= prompt_notes | llm_fast\n",
    "\n",
    "  # Prepare common input data\n",
    "  input_data = {\n",
    "        'objects_documentation': state['objects_documentation'], \n",
    "        'question': state['current_question'], \n",
    "        'messages_log': extract_msg_content_from_history(state['messages_log'])\n",
    "   }\n",
    "\n",
    "  # determine if clear or ambiguous\n",
    "  result_1 = chain_1.invoke(input_data)\n",
    "\n",
    "  # Based on result, invoke appropriate chain\n",
    "  if result_1['analytical_intent_clearness'] == \"Analytical Intent Extracted\":\n",
    "        # create analytical intents\n",
    "        input_data.update({'database_content':state['database_content']})        \n",
    "        result_2 = chain_2.invoke(input_data)\n",
    "        # next tool to call \n",
    "        tool_name = 'create_sql_query_or_queries' \n",
    "        output = {\n",
    "            'scenario': 'A',\n",
    "            'analytical_intent': result_2['analytical_intent'],\n",
    "            'notes': None\n",
    "        }\n",
    "  elif result_1['analytical_intent_clearness'] == \"Analytical Intent Ambiguous\":\n",
    "         # create analytical intents\n",
    "         result_3 = chain_3.invoke(input_data)\n",
    "         input_data.update({'analytical_intents':result_3['analytical_intent']})\n",
    "         result_4 = chain_4.invoke(input_data)\n",
    "         # next tool to call \n",
    "         tool_name = 'generate_answer'\n",
    "         output = {\n",
    "            'scenario': 'D', \n",
    "            'analytical_intent': result_3['analytical_intent'],\n",
    "            'notes': result_4.content }\n",
    "\n",
    "  # update the state \n",
    "  state['generate_answer_details'].update({'scenario':output['scenario'],\n",
    "                                           'notes':output['notes']})\n",
    "  state['analytical_intent'] = output['analytical_intent']\n",
    "  \n",
    "  # control flow\n",
    "  action = AgentAction(tool='extract_analytical_intent', tool_input='',log='tool ran successfully')\n",
    "  state['intermediate_steps'].append(action)\n",
    "  state['intermediate_steps'].append(AgentAction(tool=tool_name, tool_input='',log=''))    \n",
    "  \n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27d37d",
   "metadata": {},
   "source": [
    "## Create sql query or queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858c9a25",
   "metadata": {},
   "source": [
    "### Create_sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a830ba6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class OutputAsAQuery(TypedDict):\n",
    "  \"\"\" generated sql query or sql queries if there are multiple \"\"\"\n",
    "  query: Annotated[list[str],\"clean sql query\"]\n",
    "\n",
    "@tool\n",
    "def create_sql_query_or_queries(state:State):\n",
    "  \"\"\" creates sql query/queries to anwser a question based on documentation of tables and columns available \"\"\"\n",
    "\n",
    "  system_prompt = \"\"\"You are a sql expert and an expert data modeler.  \n",
    "\n",
    "  Your task is to create sql scripts in {sql_dialect} dialect to answer the analytical intent(s). In each sql script, use only these tables and columns you have access to:\n",
    "  {objects_documentation}\n",
    "\n",
    "  Analytical intent(s):\n",
    "  {analytical_intent}\n",
    "\n",
    "  Answer just with the resulting sql code(s).\n",
    "\n",
    "  Important quality requirements for every sql string:\n",
    "    - Return one sql string for every analytical intent.\n",
    "    - Return only raw SQL strings in the list.\n",
    "    - DO NOT include comments (like \"-- Query 1\"), labels, or explanations.\n",
    "    - If only one SQL query is needed, just return a list with that one query.\n",
    "    - GROUP BY expressions must match the non-aggregated SELECT expressions.\n",
    "    - Ensure that any expression used in ORDER BY also appears in the SELECT clause.\n",
    "    - If you filter by specific text values, use trim and lowercase (ex: \"where trim(lower(column_name)) = trim(lower(\"ValueTofilterBy\")) \"). \n",
    "    - Keep query performance in mind. \n",
    "      Example: Avoid CROSS JOIN by using a (scalar) subquery directly in CASE statements.\n",
    "\n",
    "  Important considerations about multi-steps analytical intents (the ones that contain \"Step 1:\", \"Step 2:\" etc):\n",
    "  Create a sophisticated SQL query using CTEs that mirror the steps:\n",
    "  - Each \"Step X\" becomes a corresponding CTE.\n",
    "  - Name CTEs descriptively based on what each step accomplishes.\n",
    "  - Build each CTE using results from previous CTEs.\n",
    "  - Final SELECT provides the complete analysis.   \n",
    "\n",
    "  Example output (simple, non multi-steps):\n",
    "    [\n",
    "      \"SELECT COUNT(*) FROM feedback;\",\n",
    "      \"SELECT AVG(product_price) FROM products;\"\n",
    "    ]\n",
    "\n",
    "   Example output (multi-steps):\n",
    "    [\n",
    "      \"    WITH step1_descriptive_name AS (\n",
    "        -- Implementation of Step 1 from analytical intent\n",
    "        SELECT ...\n",
    "    ),\n",
    "    step2_descriptive_name AS (\n",
    "        -- Implementation of Step 2, using step1 results\n",
    "        SELECT ... FROM step1_descriptive_name ...\n",
    "    ),\n",
    "    step3_final_analysis AS (\n",
    "        -- Implementation of Step 3, final analysis\n",
    "        SELECT ... FROM step2_descriptive_name ...\n",
    "    )\n",
    "    SELECT\n",
    "        clear_result_columns,\n",
    "        meaningful_calculations,\n",
    "        percentage_or_comparison_metrics\n",
    "    FROM step3_final_analysis\n",
    "    ORDER BY logical_sort_order;\"\n",
    "    ]  \n",
    "  \"\"\"\n",
    "\n",
    "  prompt = ChatPromptTemplate.from_messages([('system', system_prompt)])\n",
    "\n",
    "  chain = prompt | llm.with_structured_output(OutputAsAQuery)\n",
    "\n",
    "  result = chain.invoke({'objects_documentation':state['objects_documentation'], 'analytical_intent': state['analytical_intent'],'sql_dialect':state['sql_dialect']})\n",
    "  for q in result['query']:\n",
    "   state['current_sql_queries'].append( {'query': q,\n",
    "                                     'explanation': '', ## add it later\n",
    "                                     'result':'', ## add it later\n",
    "                                     'insight': '', ## add it later\n",
    "                                     'metadata':'' ## add it later\n",
    "                                      } )\n",
    "  \n",
    "  print(f\"✅ SQL queries created:{len(state['current_sql_queries'])}\")\n",
    "  \n",
    "  # control flow\n",
    "  action = AgentAction(tool='create_sql_query_or_queries', tool_input='',log='tool ran successfully')\n",
    "  state['intermediate_steps'].append(action)  \n",
    "  return state\n",
    "\n",
    "# since gpt-4o allows a maximum completion limit (output context limit) of 4k tokens, I half it to get maximum context size, so 2k. Assuming the entire context is not just the data,\n",
    "# I divide this number by 5 and arrive at a limit of 400 tokens for the result of the sql query.\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "maximum_nr_tokens_sql_query = 500\n",
    "\n",
    "# create a function that counts the tokens from a string\n",
    "def count_tokens(string:str):\n",
    " \"\"\" returns the number of tokens in a text string \"\"\"\n",
    " encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    " num_tokens = len(encoding.encode(string))\n",
    " return num_tokens\n",
    "\n",
    "# create a function that compares the tokens from the sql query result with the maximum token limit, and returns true if the context limit has been exceeded, false otherwise.\n",
    "def check_if_exceed_maximum_context_limit(sql_query_result):\n",
    " \"\"\" compares the tokens from the sql query result with the maximum token limit, and returns true if the context limit has been exceeded, false otherwise \"\"\"\n",
    " tokens_sql_query_result = count_tokens(sql_query_result)\n",
    " if tokens_sql_query_result > maximum_nr_tokens_sql_query:\n",
    "  return True\n",
    " else:\n",
    "  return False  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0992424",
   "metadata": {},
   "source": [
    "### Create query analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d949731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryAnalysis(TypedDict):\n",
    "    ''' complete analysis of a sql query, including its explanation, limitation and insight '''\n",
    "    explanation: str\n",
    "    limitation: str\n",
    "    insight: str\n",
    "\n",
    "def create_query_analysis(sql_query:str, sql_query_result:str):\n",
    "   ''' creates: explanation - a concise explanation of what the sql query does.\n",
    "                limitation - a concise explanation of the sql query by pointing out its limitations.\n",
    "                insight - insight from the result of the sql query.\n",
    "   '''\n",
    "   system_prompt = \"\"\"\n",
    "   You are an expert data analyst.\n",
    "\n",
    "   You are provided with the following SQL query:\n",
    "   {sql_query}.\n",
    "\n",
    "   Which yielded the following result:\n",
    "   {sql_query_result}.\n",
    "\n",
    "   Provide a structured analysis with three components:\n",
    "\n",
    "   Step 1: Explanation: A concise description of what the query outputs, in one short phrase. \n",
    "                   Do not include introductory words like \"The query\" or \"It outputs.\"\n",
    "\n",
    "   Step 2: Limitation: Inherent limitations or assumptions of the query based strictly on its structure and logic.\n",
    "                  Focus on:\n",
    "                  - How LIMIT, ORDER BY, GROUP BY, or JOINs may introduce assumptions\n",
    "                  - How filtering or aggregation logic may bias the output\n",
    "                  - Situations where the query might **return incomplete or misleading results due to logic only**\n",
    "                  - Cases where ORDER BY combined with LIMIT might exclude other rows with equal values (ties)\n",
    "\n",
    "                  Only describe things that follow **logically from the query**, not from the dataset itself.\n",
    "\n",
    "                  🚫 Do NOT mention:\n",
    "                  - speculate on what the user is trying to analyze\n",
    "                  - suggest what insights are missing\n",
    "                  - mention field names being correct or incorrect\n",
    "                  - mention data types, nulls, formatting, spelling, or schema correctness\n",
    "                  - mention what other attributes, columns, filters, or relationships \"could have\" been used\n",
    "                  - assume anything about the intent behind the query\n",
    "\n",
    "                  If the query has no structural limitations or assumptions, respond with exactly \"No comments for the query\".\n",
    "\n",
    "                  Respond in 1 to 3 concise sentences, or with the exact phrase above.\n",
    "   \n",
    "   Step 3: Insight: Key findings from the results, stating facts directly without technical terms.\n",
    "               - Include the limitations discovered in step 2, as long as it's different than \"No comments for the query\".\n",
    "               - Do not mention your subjective assessment over the results.\n",
    "               - Avoid technical terms like \"data\",\"dataset\",\"table\",\"list\",\"provided information\",\"query\" etc.\n",
    "   \"\"\"\n",
    "\n",
    "   prompt = ChatPromptTemplate.from_messages(('system',system_prompt))\n",
    "   chain = prompt | llm_fast.with_structured_output(QueryAnalysis)\n",
    "   return chain.invoke({'sql_query':sql_query,\n",
    "                        'sql_query_result':sql_query_result})   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc11ef",
   "metadata": {},
   "source": [
    "### Create query metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231961b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "from sqlglot import parse_one, exp\n",
    "\n",
    "def extract_metadata_from_sql_query(sql_query):\n",
    "   # returns a dictionary with parsed names of tables and columns used in filters, aggregations and groupings \n",
    "   \n",
    " ast = parse_one(sql_query)\n",
    "\n",
    " sql_query_metadata = {\n",
    "    \"tables\": [],\n",
    "    \"filters\": [],\n",
    "    \"aggregations\": [],\n",
    "    \"groupings\": []\n",
    " }\n",
    "\n",
    " # extract tables\n",
    " table_generator = ast.find_all(sqlglot.expressions.Table)\n",
    " for items in table_generator:\n",
    "    sql_query_metadata['tables'].append(items.sql())\n",
    " # remove dups\n",
    " sql_query_metadata['tables'] = list(dict.fromkeys(sql_query_metadata['tables']))\n",
    "\n",
    " # extract filters\n",
    " where_conditions = ast.find_all(sqlglot.expressions.Where)\n",
    " for item in where_conditions:\n",
    "  sql_query_metadata['filters'].append(item.this.sql())\n",
    "  # remove dups\n",
    " sql_query_metadata['filters'] = list(dict.fromkeys(sql_query_metadata['filters']))\n",
    "\n",
    " # extract aggregate functions\n",
    " funcs = ast.find_all(sqlglot.expressions.AggFunc)\n",
    " for item in funcs:\n",
    "  sql_query_metadata['aggregations'].append(item.sql())\n",
    " # remove dups\n",
    " sql_query_metadata['aggregations'] = list(dict.fromkeys(sql_query_metadata['aggregations']))\n",
    "\n",
    " # extract groupings\n",
    " groupings = ast.find_all(sqlglot.expressions.Group)\n",
    " for item in groupings:\n",
    "  groupings_flattened = item.flatten()\n",
    "  for item in groupings_flattened:\n",
    "    sql_query_metadata['groupings'].append(item.sql())\n",
    " # remove dups\n",
    " sql_query_metadata['groupings'] = list(dict.fromkeys(sql_query_metadata['groupings']))\n",
    "\n",
    " return {'tables':sql_query_metadata.get('tables'),\n",
    "         'filters':sql_query_metadata.get('filters'),\n",
    "         'aggregations':sql_query_metadata.get('aggregations'),\n",
    "         'groupings':sql_query_metadata.get('groupings'),\n",
    "          }\n",
    "\n",
    "def format_sql_metadata_explanation(tables:list=None, filters:list=None, aggregations:list=None, groupings:list=None,header :str='') -> str:\n",
    "    # creates a string explanation of the filters, tables, aggregations and groupings used by the query\n",
    "    explanation = header\n",
    "\n",
    "    if tables:\n",
    "        explanation += \"\\n\\n🧊 Tables: • \" + \" • \".join(tables)\n",
    "    if filters:\n",
    "        explanation += \"\\n\\n🔍 Filters applied: • \" + \" • \".join(filters)\n",
    "    if aggregations:\n",
    "        explanation += \"\\n\\n🧮 Aggregations: • \" + \" • \".join(aggregations)\n",
    "    if groupings:\n",
    "        explanation += \"\\n\\n📦 Groupings: • \" + \" • \".join(groupings)\n",
    "\n",
    "    return explanation.strip()\n",
    "\n",
    "def create_query_metadata(sql_query: str):\n",
    " \"\"\" creates an explanation for one single query \"\"\"\n",
    "\n",
    " metadata = extract_metadata_from_sql_query(sql_query)\n",
    " return format_sql_metadata_explanation(metadata['tables'],metadata['filters'],metadata['aggregations'],metadata['groupings'])\n",
    "\n",
    "\n",
    "def create_queries_metadata(sql_queries: list[dict]):\n",
    " \"\"\" creates an explanation for multiple queries: used in the generate_answer tool \"\"\"\n",
    "\n",
    " all_tables = []\n",
    " all_filters = []\n",
    " #all_aggregations = []\n",
    " #all_groupings = []\n",
    "\n",
    " for q in sql_queries: \n",
    "\n",
    "  metadata = extract_metadata_from_sql_query(q['query'])\n",
    "  all_tables.extend(metadata[\"tables\"])\n",
    "  all_filters.extend(metadata[\"filters\"])\n",
    "  #all_aggregations.extend(metadata[\"aggregations\"])\n",
    "  #all_groupings.extend(metadata[\"groupings\"])\n",
    "  \n",
    "  # include all metadata\n",
    "  #output = format_sql_metadata_explanation(all_tables,all_filters,all_aggregations,all_groupings,header='🔍 Filters applied:')\n",
    "\n",
    "  # include the default min/max feedback filters if feedback table has been used and was not filtered at all\n",
    "  if 'feedback' in all_tables and not any('feedback_date' in item for item in all_filters):\n",
    "     all_filters.append('feedback_date between 11/18/2002 and 09/12/2023')\n",
    "     output = format_sql_metadata_explanation(filters = all_filters,header='')\n",
    "  # include just the filters if there are any\n",
    "  elif all_filters:    \n",
    "     output = format_sql_metadata_explanation(filters = all_filters,header='')\n",
    "  # if no filters were applied, don't include other metadata for the sake of keeping the message simple\n",
    "  else:\n",
    "     output = ''   \n",
    "\n",
    " return output\n",
    "\n",
    "# use it like so:\n",
    "#sql_queries = [ \n",
    "#    {'query':'SELECT COUNT(DISTINCT company.company_name) FROM company;', 'result':''} ,\n",
    "#    {'query':'SELECT COUNT(DISTINCT feedback.feedback_id) FROM feedback;', 'result':''} \n",
    "#    ]\n",
    "#create_queries_metadata(sql_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f0462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # former Retrieve insights tool\n",
    "# import re\n",
    "\n",
    "# def create_or_retrieve_vector_store():\n",
    "#  global vector_store  \n",
    "#  if vector_store is None:\n",
    "#     vector_store = InMemoryVectorStore(embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "#  return vector_store\n",
    "\n",
    "# def parse_explanation(content:str):\n",
    "#     ''' from a text with a format of Query Explanation: ... Query Insight: ...  parse just the explanation part '''\n",
    "#     match = re.search(r\"Query Explanation:(.*?)Query Insight:\", content, re.DOTALL)\n",
    "#     explanation = match.group(1).strip()  # removes leading/trailing whitespace including \\n\n",
    "#     return explanation\n",
    "\n",
    "# @tool\n",
    "# def retrieve_insights(state:State):\n",
    "#   ''' Searches the vector store for relevant past query insights with similarity > 0.6 and appends them to state['current_sql_queries'] '''\n",
    "#   print(\"💭 Gathering my thoughts...\")\n",
    "#   vector_store = create_or_retrieve_vector_store()\n",
    "#   for query in enumerate(state['analytical_intent']):\n",
    "#     query=query[1]\n",
    "#     result = vector_store.similarity_search_with_score(query,k=3)\n",
    "#     for doc,score in result:\n",
    "#      if score >= 0.6:   \n",
    "#       state['current_sql_queries'].append( {'query': doc.metadata.get('query'),\n",
    "#                                      'explanation': parse_explanation(doc.page_content), \n",
    "#                                      'result':doc.metadata.get('result'), \n",
    "#                                      'insight': doc.metadata.get('insight'),\n",
    "#                                      'metadata':doc.metadata.get('metadata')\n",
    "#                                       } ) \n",
    "#   # control flow\n",
    "#   action = AgentAction(tool='retrieve_insights', tool_input='',log='tool ran successfully')\n",
    "#   state['intermediate_steps'].append(action)  \n",
    "\n",
    "#   return state  \n",
    "\n",
    "# In execute sql query tool:\n",
    "         # add the queries to vector store\n",
    "         #vector_store = create_or_retrieve_vector_store()\n",
    "         #doc = [Document(\n",
    "         #     id=len(vector_store.store)+1,\n",
    "         #     page_content=f\"Query Explanation:\\n{analysis['explanation'] }\\n\\Query Insight:{analysis['insight']}\",\n",
    "         #     metadata={\"query\": sql_query,\n",
    "         #               \"result\": sql_query_result,\n",
    "         #               \"insight\": analysis['insight'],\n",
    "         #               \"metadata\": sql_query_metadata\n",
    "         #               })]\n",
    "         #vector_store.add_documents(documents=doc)                                                          \n",
    "         #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d1c989",
   "metadata": {},
   "source": [
    "## Execute (& refine) sql query and stores result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78535456",
   "metadata": {},
   "source": [
    "### Execute sql query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f766366d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# the function checks if the query output exceeds context window limit and if yes, send the query for refinement\n",
    "\n",
    "from langchain_community.tools import QuerySQLDataBaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from typing import Iterator\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class OutputAsASingleQuery(TypedDict):\n",
    "  \"\"\" generated sql query \"\"\"\n",
    "  query: Annotated[str,...,\"clean sql query\"]\n",
    "\n",
    "\n",
    "def correct_syntax_sql_query(sql_query: str, error:str, objects_documentation: str, database_content: str, sql_dialect: str):\n",
    " \"\"\" corrects the syntax of sql query \"\"\"\n",
    "\n",
    " system_prompt = \"\"\"\n",
    "  Correct the following sql query which returns an error caused by wrong syntax.  \n",
    "\n",
    "  Sql query to correct: {sql_query}.\n",
    "  Error details: {error}.\n",
    "\n",
    "  *** Important considerations for correcting the sql query ***\n",
    "      - Make sure the query is valid in {sql_dialect} dialect.\n",
    "      - Use only these tables and columns you have access to: {objects_documentation}.\n",
    "      - Summary of database content: {database_content}.\n",
    "      - If possible, simplify complex operations (e.g., percentile estimation) using built-in functions compatible with SQLite.\n",
    "      - Keep query performance in mind. \n",
    "        Example: Avoid CROSS JOIN by using a (scalar) subquery directly in CASE statements.\n",
    "\n",
    "  Output the corrected version of the query.\n",
    "  \"\"\"\n",
    " \n",
    " prompt = ChatPromptTemplate.from_messages(('system',system_prompt))\n",
    " chain = prompt | llm.with_structured_output(OutputAsASingleQuery)\n",
    " result = chain.invoke({'sql_query':sql_query,'error':error,'objects_documentation':objects_documentation,'database_content':database_content, 'sql_dialect':sql_dialect})\n",
    " sql_query = result['query']\n",
    " return sql_query\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "\n",
    "def execute_sql_query(state:State):\n",
    "  \"\"\" executes the sql query and retrieve the result \"\"\"\n",
    "  \n",
    "  print(\"⚙️ Analysing results...\")\n",
    "  for query_index, q in enumerate(state['current_sql_queries']):\n",
    "     \n",
    "    if state['current_sql_queries'][query_index]['result'] == '':    \n",
    "     sql_query = q['query'] \n",
    "    \n",
    "     # refine the query 3 times if necessary.\n",
    "     for i in range(3):\n",
    "\n",
    "       # executes the query and if it throws an error, correct it (max 3x times) then execute it again.\n",
    "       sql_query_result = QuerySQLDataBaseTool(db=db).invoke(sql_query)\n",
    "       attempt = 0\n",
    "       while 'Error' in sql_query_result and attempt < 3:   \n",
    "            error = sql_query_result\n",
    "            sql_query = correct_syntax_sql_query(sql_query,error,objects_documentation,database_content,state['sql_dialect'])\n",
    "            sql_query_result = QuerySQLDataBaseTool(db=db).invoke(sql_query)\n",
    "            attempt += 1\n",
    "\n",
    "       # if the sql query does not exceed output context window return its result\n",
    "       if not check_if_exceed_maximum_context_limit(sql_query_result):\n",
    "         analysis = create_query_analysis(sql_query, sql_query_result)\n",
    "         sql_query_metadata = create_query_metadata(sql_query)   \n",
    "\n",
    "         # Update state\n",
    "         state['current_sql_queries'][query_index]['result'] = sql_query_result\n",
    "         state['current_sql_queries'][query_index]['insight'] = analysis['insight']\n",
    "         state['current_sql_queries'][query_index]['query'] = sql_query\n",
    "         state['current_sql_queries'][query_index]['metadata'] = sql_query_metadata\n",
    "         state['current_sql_queries'][query_index]['explanation'] = analysis['explanation']\n",
    "         break   \n",
    "\n",
    "       # if the sql query exceeds output context window and there is more room for iterations, refine the query\n",
    "       else:\n",
    "        print(f\"🔧 Refining query {query_index+1}/{len(state['current_sql_queries'])} as its output its too large...\")\n",
    "        sql_query = refine_sql_query(state['analytical_intent'],sql_query,state['objects_documentation'],state['database_content'],state['sql_dialect'])['query']\n",
    "\n",
    "       # if there is no more room for sql query iterations and the result still exceeds context window, throw a message\n",
    "    else:\n",
    "        print(f\"⚠️ Query result too large after 3 refinements.\")\n",
    "        state['current_sql_queries'][query_index]['result'] = 'Query result too large after 3 refinements.'\n",
    "        state['current_sql_queries'][query_index]['explanation'] = \"Refinement failed.\"\n",
    "      \n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e660ade",
   "metadata": {},
   "source": [
    "### Query Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7489351",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def refine_sql_query(analytical_intent: str, sql_query: str, objects_documentation: str, database_content: str, sql_dialect:str):\n",
    " \"\"\" refines the sql query so that its output tokens do not exceed the maximum context limit \"\"\"\n",
    "\n",
    " system_prompt = \"\"\"\n",
    "  As a sql expert, your task is to optimize a sql query that returns more than 20 rows or exceeds the token limit.\n",
    "  \n",
    "  You are trying to answer the following analytical intent: {analytical_intent}.\n",
    "  Sql query to optimize: {sql_query}.\n",
    "\n",
    "  *** Important considerations for creating the sql query ***\n",
    "  - Make sure the query is valid in {sql_dialect} dialect.\n",
    "  - Use only these tables and columns you have access to: {objects_documentation}.\n",
    "  - Summary of database content: {database_content}.\n",
    "  \n",
    "  *** Optimization Examples ***  \n",
    "  \n",
    "  A. Apply aggregation functions instead of returning a list of records.\n",
    "      Example: - Analytical intent: \"number of distinct ids in table where column equals 5\"\n",
    "               - Original sql query: \"SELECT DISTINCT id FROM table WHERE column = 5;\"\n",
    "\t\t\t         - Refined sql query: \"SELECT COUNT(DISTINCT id) FROM table WHERE column = 5;\"\n",
    "\t\t\t\n",
    "  B. Group the data at a higher granularity.\n",
    "     Example: If sql query shows data by days, group by months and return last N months.\n",
    "  \n",
    "  C. Group the data in buckets.\n",
    "      Example: - Analytical intent: \"Analyze the relationship between products.product_price and products.product_average-rating in the products table to determine if product price influences average rating.\"\n",
    "               - Original sql query: \"SELECT product_price, product_average_rating FROM products GROUP BY product_price, product_average_rating\"\n",
    "\t\t\t         - Refined sql query: \"SELECT \n",
    "                                         CASE \n",
    "                                             WHEN product_price < 10 THEN '<$10'\n",
    "                                             WHEN product_price >= 10 AND product_price < 50 THEN '$10–$50'\n",
    "                                             ELSE '$50+'\n",
    "                                             END AS price_bucket,\n",
    "                                         CASE \n",
    "                                             WHEN product_price < 10 THEN 1\n",
    "                                             WHEN product_price >= 10 AND product_price < 50 THEN 2\n",
    "                                             ELSE 3\n",
    "                                             END AS price_bucket_sort,                                             \n",
    "                                         ROUND(AVG(product_average_rating), 2) AS avg_rating,\n",
    "                                         COUNT(*) AS product_count\n",
    "                                   FROM products\n",
    "                                   GROUP BY price_bucket\n",
    "                                   ORDER BY price_bucket_sort;\"\n",
    "   \n",
    "  \n",
    "  D. Apply filters.\n",
    "     Examples: - Time-based filters: Show records for the last 3 months. Use database content to identify the temporal context for this conversation.\n",
    "              -  filter for a single company. Use database content to identify specific values. \n",
    "  \n",
    "  E. Show top records.\n",
    "     Provide a snapshot of data by retrieving maximum 20 rows and 5 columns.\n",
    "     Example: The Analytical intent is: \"average sale per customer\", but there are too many customers, so show top N.\n",
    "                       - Original sql query: \"SELECT customer_name, avg(sale) as avg_sale from sales group by customer_name\"\n",
    "\t\t\t                 - Refined sql query: \"SELECT customer_name, avg(sale) as avg_sale from sales group by customer_name ORDER BY avg_sale desc limit 10;\"\n",
    "\n",
    "  *** Optimization Guidelines ***  \n",
    "      1. Do not eliminate key dimensions that are explicitly part of the analytical intent.  \n",
    "         For example, if the user asks for time based analysis per customer, do not drop time or customer attributes. \n",
    "         Instead, you can use optimization example D (filter date range) or example B (aggregate time at higher level).                   \n",
    "  \"\"\"\n",
    " \n",
    " prompt = ChatPromptTemplate.from_messages(('system',system_prompt))\n",
    " chain = prompt | llm.with_structured_output(OutputAsASingleQuery)\n",
    "\n",
    " sql_query = chain.invoke({'analytical_intent': analytical_intent,\n",
    "               'sql_query':sql_query,\n",
    "               'objects_documentation':objects_documentation,\n",
    "               'database_content':database_content,\n",
    "               'sql_dialect':sql_dialect}\n",
    "               )\n",
    " return sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8952f76b",
   "metadata": {},
   "source": [
    "## Generate answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4fe022",
   "metadata": {},
   "source": [
    "### Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c4a66a",
   "metadata": {},
   "source": [
    "Scenarios for generate_answer responses:\n",
    "\n",
    "A. Default flow. When insights are retrieved to answer the question, from queries or vector store. -> \"Scenario A\".\n",
    "\n",
    "B. answer is in the chat history, or the question is pleasantries -> \"Scenario B\".\n",
    "\n",
    "C. request is not in db schema -> \"Scenario C\".\n",
    "\n",
    "D. Analytical intent ambigous -> \"Scenario D\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b223d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # response guidelines to be added at the end of every prompt\n",
    "response_guidelines = '''\n",
    "  Response guidelines:\n",
    "  - Respond in clear, non-technical language. \n",
    "  - Be concise. \n",
    "\n",
    "  Use these methods at the right time, optionally and not too much, keep it simple and conversational:\n",
    "\n",
    "  If the question is smart, reinforce the user’s question to build confidence. \n",
    "    Example: “Great instinct to ask that - it’s how data-savvy pros think!”\n",
    "\n",
    "  If the context allows, suggest max 2 next steps to explore further. \n",
    "  Suggest next steps that can only be achieved with the database schema you have access to:\n",
    "  {objects_documentation}\n",
    "\n",
    "  Summary of database content:\n",
    "  {database_content}.\n",
    "  \n",
    "  Example of next steps:\n",
    "  - Trends over time:\n",
    "    Example: \"Want to see how this changed over time?\".\n",
    "\n",
    "  - Drill-down suggestions:\n",
    "    Example: “Would you like to explore this by brand or price tier?”\n",
    "\n",
    "  - Top contributors to a trend:\n",
    "    Example: “Want to see the top 5 products that drove this increase in satisfaction?”\n",
    "\n",
    "  - Explore a possible cause:\n",
    "    Example: “Curious if pricing could explain the drop? I can help with that.”\n",
    "\n",
    "  - Explore the data at higher granularity levels if the user analyzes on low granularity columns. Use database schema to identify such columns.\n",
    "    Example: Instead of analyzing at product level, suggest at company level.\n",
    "\n",
    "  - Explore the data on filtered time ranges. Use database content to identify the temporal context for this conversation .\n",
    "    Example: Instead of analyzing for all feedback dates, suggest filtering for a year or for a few months.   \n",
    "\n",
    "  - Filter the data on the value of a specific attribute. Use database content to identify values of important dataset attributes.\n",
    "    Example: Instead of analyzing for all companies, suggest filtering for a single company and give a few suggestions.       \n",
    "\n",
    "  Close the prompt in one of these ways:\n",
    "  A. If you suggest next steps, ask the user which option prefers.\n",
    "  B. Use warm, supportive closing that makes the user feel good. \n",
    "    Example: “Keep up the great work!”, “Have a great day ahead!”.\n",
    "  '''\n",
    "\n",
    "# Each scenario\n",
    "\n",
    "scenario_A = {  \n",
    "    'Type': 'A',\n",
    "    'Description': 'insights are retrieved to answer the question, from queries or vector store.',\n",
    "    'Prompt': \"\"\"You are a decision support consultant helping users become more data-driven.\n",
    "    Continue the conversation from the last user prompt. \n",
    "    \n",
    "    Conversation history:\n",
    "    {messages_log}.\n",
    "\n",
    "    Last user prompt:\n",
    "    {question}.  \n",
    "\n",
    "    Use both the raw SQL results and the extracted insights below to form your answer: {insights}. \n",
    "    \n",
    "    Include all details from these insights.\"\"\" + '\\n\\n' + response_guidelines.strip(),\n",
    "    'Invoke_Params': lambda state: {\n",
    "        'messages_log': state['messages_log'],\n",
    "        'question': state['current_question'],\n",
    "        'objects_documentation': state['objects_documentation'],\n",
    "        'database_content': state['database_content'],\n",
    "        'insights': format_sql_query_results_for_prompt(state['current_sql_queries']),\n",
    "        'current_sql_queries': state['current_sql_queries']\n",
    "    }\n",
    "}\n",
    "\n",
    "scenario_B = {  \n",
    "    'Type': 'B',\n",
    "    'Description': 'answer is in the chat history, or the question is pleasantries. With response guidelines',\n",
    "    'Prompt': \"\"\" You are a decision support consultant helping users become more data-driven.\n",
    "    Continue the conversation from the last user prompt. \n",
    "    \n",
    "    Conversation history:\n",
    "    {messages_log}.\n",
    "\n",
    "    Last user prompt:\n",
    "    {question}.\"\"\" + '\\n\\n' + response_guidelines.strip(),\n",
    "    'Invoke_Params': lambda state: {\n",
    "        'messages_log': state['messages_log'],\n",
    "        'question': state['current_question'],\n",
    "        'objects_documentation': state['objects_documentation'],\n",
    "        'database_content': state['database_content']\n",
    "    }\n",
    "}\n",
    "\n",
    "scenario_C = {  \n",
    "    'Type': 'C',\n",
    "    'Description': 'request is not in db schema',\n",
    "    'Prompt': \"\"\"You are a decision support consultant helping users become more data-driven.\n",
    "    Continue the conversation from the last user prompt. \n",
    "    \n",
    "    Conversation history:\n",
    "    {messages_log}.\n",
    "\n",
    "    Last user prompt:\n",
    "    {question}.\n",
    "    \n",
    "    Unfortunately, the requested information from last prompt is not available in our database. Here are the details: {notes}.\n",
    "    \n",
    "    Use the response guidelines below to explain what information is not available by suggesting alternative analyses that can be performed with the available data.\"\"\" + '\\n\\n' + response_guidelines.strip(),\n",
    "    'Invoke_Params': lambda state: {\n",
    "        'messages_log': state['messages_log'],\n",
    "        'question': state['current_question'],\n",
    "        'objects_documentation': state['objects_documentation'],\n",
    "        'database_content': state['database_content'],\n",
    "        'notes': state['generate_answer_details']['notes']\n",
    "    }\n",
    "}\n",
    "\n",
    "scenario_D = {  \n",
    "    'Type': 'D',\n",
    "    'Description': 'Analytical intent ambiguous',\n",
    "    'Prompt': \"\"\"You are a decision support consultant helping users become more data-driven.\n",
    "    \n",
    "    Continue the conversation from the last user prompt. \n",
    "    \n",
    "    Conversation history:\n",
    "    {messages_log}.\n",
    "\n",
    "    Last user prompt:\n",
    "    {question}.\n",
    "    \n",
    "    The last user prompt could be interpreted in multiple ways. Here's what makes it ambiguous: {notes}.\n",
    "    \n",
    "    Acknowledge what makes the question ambiguous, present different options as possible interpretations and ask the user to specify which analysis it wants.\n",
    "\n",
    "    Respond in clear, non-technical language. Be concise.\"\"\" + '\\n\\n' + response_guidelines.strip(),\n",
    "    'Invoke_Params': lambda state: {\n",
    "        'messages_log': state['messages_log'],\n",
    "        'question': state['current_question'],\n",
    "        'objects_documentation': state['objects_documentation'],\n",
    "        'database_content': state['database_content'],\n",
    "        'notes': state['generate_answer_details']['notes']\n",
    "    }\n",
    "}\n",
    "\n",
    "scenario_prompts = [scenario_A,scenario_B,scenario_C,scenario_D]\n",
    "# use it like so, to retrieve prompt for scenario A: next(s['Prompt'] for s in scenario_prompts if s['Type'] == 'A')\n",
    "\n",
    "def format_sql_query_results_for_prompt (sql_queries : list[dict]) -> str:\n",
    "    \n",
    "    formatted_queries = []\n",
    "    for query_index,q in enumerate(sql_queries):\n",
    "        block = f\"Insight {query_index+1}:\\n{q['insight']}\\n\\nRaw Result of insight {query_index+1}:\\n{q['result']}\"\n",
    "        formatted_queries.append(block)\n",
    "    return \"\\n\\n\".join(formatted_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b077cdd8",
   "metadata": {},
   "source": [
    "### Generate answer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21ae8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a function that generates the agent answer based on sql query result\n",
    "\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "@tool\n",
    "def generate_answer(state:State):\n",
    "  \"\"\" generates the AI answer taking into consideration the explanation and the result of the sql query that was executed \"\"\"\n",
    "  \n",
    "  scenario = state['generate_answer_details']['scenario']\n",
    "\n",
    "  # create prompt template based on scenario\n",
    "  sys_prompt = next(s['Prompt'] for s in scenario_prompts if s['Type'] == scenario)\n",
    "  prompt = ChatPromptTemplate.from_messages([MessagesPlaceholder(\"messages_log\"),('system',sys_prompt)] )\n",
    "  llm_answer_chain = prompt | llm\n",
    "\n",
    "  if scenario == 'A': # show filters\n",
    "    final_answer_chain = { 'llm_answer': llm_answer_chain\n",
    "                         ,'input_state': RunnablePassthrough()  \n",
    "                           } | RunnableLambda (lambda x: { 'ai_message': AIMessage( content = f\"{x['llm_answer'].content.strip()}\\n\\n{create_queries_metadata(x['input_state']['current_sql_queries'])}\"\n",
    "                                                                         ,response_metadata = x['llm_answer'].response_metadata  ) } ) \n",
    "  else: # filters not necessary\n",
    "    final_answer_chain = { 'llm_answer': llm_answer_chain\n",
    "                          , 'input_state': RunnablePassthrough() \n",
    "                          } | RunnableLambda (lambda x: { 'ai_message': AIMessage( content = f\"{x['llm_answer'].content}\"\n",
    "                                                                        ,response_metadata = x['llm_answer'].response_metadata  ) } )      \n",
    "\n",
    "  # invoke parameters based on scenario\n",
    "  invoke_params = next(s['Invoke_Params'](state) for s in scenario_prompts if s['Type'] == scenario)\n",
    "\n",
    "  result = final_answer_chain.invoke(invoke_params)\n",
    "  ai_msg = result['ai_message']\n",
    "\n",
    "  # Add token count for SQL metadata if applicable\n",
    "  if scenario == 'A':\n",
    "    explanation_token_count = llm.get_num_tokens(create_queries_metadata(state['current_sql_queries']))\n",
    "    ai_msg.response_metadata['token_usage']['total_tokens'] += explanation_token_count\n",
    "  \n",
    "  # Update state (common for all scenarios)\n",
    "  state['llm_answer'] = ai_msg\n",
    "  state['messages_log'].append(HumanMessage(state['current_question']))\n",
    "  state['messages_log'].append(ai_msg) \n",
    "\n",
    "  print(\"\\n📣 Final Answer:\\n\")\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68cae6",
   "metadata": {},
   "source": [
    "### Manage memory and chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f942bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_memory_chat_history(state:State):\n",
    "    \"\"\" Manages the chat history so that it does not become too large in terms of output tokens.\n",
    "    Specifically, it checks if the chat history is larger than 1000 tokens. If yes, keep just the last 4 pairs of human prompts and AI responses, and summarize the older messages.\n",
    "    Additionally, check if the logs of sql queries is larger than 20 entries. If yes, delete the older records. \"\"\"           \n",
    "\n",
    "    tokens_chat_history = state['messages_log'][-1].response_metadata.get('token_usage', {}).get('total_tokens', 0) if state['messages_log'] else 0    \n",
    "\n",
    "    if tokens_chat_history >= 1000 and len(state['messages_log']) > 4:\n",
    "        message_history_to_summarize = [msg.content for msg in state['messages_log'][:-4]]\n",
    "        prompt = ChatPromptTemplate.from_messages( [('user', 'Distill the below chat messages into a single summary paragraph.The summary paragraph should have maximum 400 tokens.Include as many specific details as you can.Chat messages:{message_history_to_summarize}') ])\n",
    "        runnable = prompt | llm_fast # use the cheap model\n",
    "        chat_history_summary = runnable.invoke({'message_history_to_summarize':message_history_to_summarize})\n",
    "        last_4_messages = state['messages_log'][-4:]\n",
    "        state['messages_log'] = [chat_history_summary] +[*last_4_messages]\n",
    "    else:\n",
    "        state['messages_log'] = state['messages_log']\n",
    "\n",
    "    # Truncate SQL logs to the most recent 20\n",
    "    #if len(state['log_sql_queries']) > 20:\n",
    "    #    state['log_sql_queries']= state['log_sql_queries'][-20:]    \n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e8d9d",
   "metadata": {},
   "source": [
    "## Orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e9e86",
   "metadata": {},
   "source": [
    "### Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24098660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_scratchpad(state:State):\n",
    " ''' retrieves the number of executions for important tools or functions (from intermediate steps) executed by the agent ''' \n",
    " nr_executions_orchestrator= 0\n",
    " nr_executions_extract_analytical_intent = 0\n",
    " nr_executions_create_sql_query_or_queries = 0\n",
    " \n",
    " for index,action in enumerate(state['intermediate_steps']):\n",
    "      \n",
    "  if action.tool == 'extract_analytical_intent' and action.log == 'tool ran successfully':\n",
    "      nr_executions_extract_analytical_intent +=1\n",
    "\n",
    "  if action.tool == 'create_sql_query_or_queries' and action.log == 'tool ran successfully':\n",
    "      nr_executions_create_sql_query_or_queries +=1\n",
    "\n",
    "  if action.tool == 'orchestrator' and action.log == 'tool ran successfully':\n",
    "     nr_executions_orchestrator +=1    \n",
    "\n",
    " output = {'nr_executions_orchestrator':nr_executions_orchestrator,\n",
    "           'nr_executions_extract_analytical_intent':nr_executions_extract_analytical_intent,\n",
    "           'nr_executions_create_sql_query_or_queries':nr_executions_create_sql_query_or_queries}   \n",
    " return output \n",
    "  \n",
    "def get_next_tool(state:State):\n",
    "  ''' creates a list of actions taken by the agent from the scratchpad '''  \n",
    "  scratchpad = retrieve_scratchpad(state)\n",
    "  nr_executions_extract_analytical_intent = scratchpad['nr_executions_extract_analytical_intent']\n",
    "  nr_executions_create_sql_query_or_queries = scratchpad['nr_executions_create_sql_query_or_queries']\n",
    "\n",
    "  if nr_executions_extract_analytical_intent == 0:\n",
    "    next_tool = 'extract_analytical_intent' \n",
    "  elif nr_executions_create_sql_query_or_queries == nr_executions_extract_analytical_intent == 1:\n",
    "    next_tool = 'generate_answer'\n",
    "\n",
    "  return next_tool\n",
    "\n",
    "class ScenarioBC(TypedDict):\n",
    "  ''' indication of the next step to be performed by the agent '''\n",
    "  next_step: Annotated[Literal[\"B\", \"C\",\"Continue\"],\"indication of the next step to be performed by the agent\"]   \n",
    "\n",
    "def orchestrator(state:State):\n",
    "  ''' Function that decides which tools to use '''\n",
    "\n",
    "  scratchpad = retrieve_scratchpad(state)\n",
    "  nr_executions_orchestrator = scratchpad['nr_executions_orchestrator']\n",
    "\n",
    "  # if this is the 1st time when orchestrator is called, check scenarios B or C to decide whether you call directly generate_answer.  \n",
    "  if nr_executions_orchestrator == 0:\n",
    "    system_prompt = f\"\"\"You are a decision support consultant helping users make data-driven decisions.\n",
    "\n",
    "    Your task is to decide the next action for this question: {{question}}.\n",
    "\n",
    "    Conversation history: {{messages_log}}. \n",
    "    Current insights: \"{{insights}}\".\n",
    "    Database schema: {{objects_documentation}}\n",
    "\n",
    "    Decision process:  \n",
    "\n",
    "    Step 1. Check if question is non-analytical or already answered:\n",
    "       - If question is just pleasantries (\"thank you\", \"hello\", \"how are you\") → \"B\"\n",
    "       - If the same question was already answered in conversation history → \"B\"\n",
    "\n",
    "    Step 2. Check if requested data exists in schema:\n",
    "      - If the user asks for data/metrics not available in the database schema → \"C\"\n",
    "    \n",
    "    Step 3. Otherwise → \"Continue\".\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([('system', system_prompt)])\n",
    "    chain = prompt | llm_fast.with_structured_output(ScenarioBC)\n",
    "    result = chain.invoke({'messages_log':extract_msg_content_from_history(state['messages_log']),\n",
    "                         'question': state['current_question'], \n",
    "                         'insights': format_sql_query_results_for_prompt(state['current_sql_queries']),\n",
    "                         'objects_documentation':state['objects_documentation']\n",
    "                         })   \n",
    "    if result['next_step'] == 'Continue':\n",
    "      scenario = None\n",
    "      notes = None \n",
    "      next_tool_name = get_next_tool(state)\n",
    "      pass  \n",
    "    \n",
    "    # if scenario B, set the scenario in the state and log the generate_answer as next step\n",
    "    elif result['next_step'] == 'B':\n",
    "      scenario = result['next_step']\n",
    "      notes = None\n",
    "      next_tool_name = 'generate_answer'\n",
    "    \n",
    "    # if scenario C, set the scenario in the state, generate the notes and log the generate_answer as next step\n",
    "    else:\n",
    "      sys_prompt_notes = \"\"\"\n",
    "      Conversation history:\n",
    "      {messages_log}.  \n",
    "\n",
    "      Last user prompt:\n",
    "      {question}. \n",
    "  \n",
    "      The user asked for data that is not available in the database schema.\n",
    "      Write a sentence suggesting an analysis with the existing schema.\n",
    "      Database schema:\n",
    "      {objects_documentation}.\n",
    "\n",
    "      Be short, concise, explain in simple, non-technical language.\n",
    "      \"\"\"\n",
    "      prompt_notes = ChatPromptTemplate.from_messages([('system', sys_prompt_notes)]) \n",
    "      chain = prompt_notes | llm_fast\n",
    "      notes_text = chain.invoke({'messages_log':extract_msg_content_from_history(state['messages_log']),\n",
    "                         'question': state['current_question'], \n",
    "                         'objects_documentation':state['objects_documentation']\n",
    "                                   })\n",
    "      scenario = result['next_step']\n",
    "      notes = notes_text.content\n",
    "      next_tool_name = 'generate_answer'\n",
    "\n",
    "  # if this is not the 1st time when orchestrator runs\n",
    "  else:\n",
    "\n",
    "    # go directly to answer because analytical intent has been extracted, queries created and executed\n",
    "    next_tool = get_next_tool(state)\n",
    "    if next_tool == 'generate_answer':\n",
    "       next_tool_name = 'generate_answer'\n",
    "       scenario = 'A' # can be changed later for the situation when insights are not enough and a subsequent analysis is needed\n",
    "       notes = None\n",
    "\n",
    "  # update generate_answer details\n",
    "  state['generate_answer_details'].update({'scenario':scenario,'notes':notes})    \n",
    "\n",
    "  # log orchestrator run\n",
    "  action = AgentAction(tool='orchestrator', tool_input='', log = 'tool ran successfully')\n",
    "  state['intermediate_steps'].append(action)     \n",
    "\n",
    "  # log next tool to call\n",
    "  action = AgentAction( tool=next_tool_name, tool_input='', log = '' )\n",
    "  state['intermediate_steps'].append(action)  \n",
    "  return state     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce9f3c",
   "metadata": {},
   "source": [
    "### Run control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a697fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the nodes\n",
    "\n",
    "def run_control_flow(state:State):\n",
    "    ''' Based on the last tool name stored in intermediate_steps (generated by the orchestrator), it executes the next node that will trigger the control flow '''\n",
    "    \n",
    "    # get the next tool to execute by looking in the last tool_name in the intermediate steps\n",
    "    tool_name = state['intermediate_steps'][-1].tool\n",
    "    \n",
    "    # extract_analytical_intent\n",
    "    if tool_name == 'extract_analytical_intent':\n",
    "      state = extract_analytical_intent.invoke({'state':state})  \n",
    "\n",
    "    # creating & executing new queries\n",
    "    elif tool_name == 'create_sql_query_or_queries':\n",
    "      state = create_sql_query_or_queries.invoke({'state':state})\n",
    "      execute_sql_query(state)\n",
    "\n",
    "    # generate answer & manage chat history.\n",
    "    elif tool_name == 'generate_answer':  \n",
    "      state = generate_answer.invoke({'state':state}) \n",
    "      manage_memory_chat_history(state)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7ce8d",
   "metadata": {},
   "source": [
    "## Assemble graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23aa439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble graph\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# function to reset the state current queries (to add in the start of graph execution)\n",
    "def reset_state(state:State):\n",
    "    state['current_sql_queries'] = []\n",
    "    state['intermediate_steps'] = []\n",
    "    state['llm_answer'] = AIMessage(content='')\n",
    "    state['generate_answer_details'] = {}\n",
    "    state['analytical_intent'] = []\n",
    "    state['objects_documentation'] = objects_documentation\n",
    "    state['database_content'] = database_content\n",
    "    state['sql_dialect'] = sql_dialect\n",
    "    return state\n",
    "\n",
    "def router(state:State):\n",
    "    # returns the tool name to use\n",
    "    return state['intermediate_steps'][-1].tool\n",
    "\n",
    "graph= StateGraph(State)\n",
    "graph.add_node(\"reset_state\",reset_state)\n",
    "graph.add_node(\"orchestrator\",orchestrator)\n",
    "\n",
    "# here you add the node corresponding to the first tool of each control flow, as the subsequent tools are run by the run_control_flow node\n",
    "graph.add_node(\"extract_analytical_intent\",run_control_flow)\n",
    "graph.add_node(\"create_sql_query_or_queries\",run_control_flow)\n",
    "graph.add_node(\"generate_answer\",run_control_flow)\n",
    "\n",
    "# starting the agent\n",
    "graph.add_edge(START,\"reset_state\")\n",
    "graph.add_edge(\"reset_state\",\"orchestrator\")\n",
    "graph.add_conditional_edges(source='orchestrator',path=router)\n",
    "graph.add_conditional_edges(source='extract_analytical_intent',path=router)\n",
    "\n",
    "# here you add a link from each the control flow node back to the orchestator - except for the generate_answer node.\n",
    "graph.add_edge(\"create_sql_query_or_queries\",\"orchestrator\")\n",
    "\n",
    "# last control flow is generate_answer\n",
    "graph.add_edge(\"generate_answer\",END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de8b960",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fcd929",
   "metadata": {},
   "source": [
    "\n",
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d7d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new conversation\n",
    "\n",
    "question = 'Are premium-priced products (top 25% by price) getting better ratings than budget products?'\n",
    "messages_log = []\n",
    "\n",
    "initial_dict = {'objects_documentation':objects_documentation,\n",
    "     'database_content':database_content,\n",
    "     'sql_dialect': sql_dialect,\n",
    "     'messages_log': messages_log,\n",
    "     'intermediate_steps':[],\n",
    "     'analytical_intent': [],\n",
    "     'current_question':question,\n",
    "     'current_sql_queries': [],\n",
    "     'generate_answer_details': {},\n",
    "     'llm_answer': AIMessage(content='')\n",
    "     }\n",
    "     \n",
    "vector_store = None  # reset vector store\n",
    "config, thread_id = create_config('Run Agent',True)\n",
    "\n",
    "result = graph.invoke(initial_dict, config = config)\n",
    "print(result['llm_answer'].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation\n",
    "question = 'yes would like to compare these with budget products in terms of average rating'\n",
    "config, _ = create_config('Run Agent',False,thread_id)\n",
    "result = graph.invoke({\n",
    "    'current_question': question\n",
    "}, config=config)\n",
    "\n",
    "print(result['llm_answer'].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b21e19",
   "metadata": {},
   "source": [
    "### Isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = None  # reset vector store\n",
    "question = 'How many companies are there?' \n",
    "test_state = {\n",
    "'objects_documentation':objects_documentation,\n",
    "'database_content':database_content,\n",
    "'sql_dialect': sql_dialect,\n",
    "'messages_log':[],\n",
    "'intermediate_steps' : [],\n",
    "'analytical_intent': [],\n",
    "'current_question':question,\n",
    "'current_sql_queries': [],\n",
    "'generate_answer_details': {},\n",
    "'llm_answer': AIMessage(content='')\n",
    "}\n",
    "orchestrator(test_state)\n",
    "test_state = run_control_flow(test_state) # extract_analytical_intent\n",
    "test_state = run_control_flow(test_state) # create sql query + execute sql query\n",
    "orchestrator(test_state)\n",
    "test_state = run_control_flow(test_state) # generate answer + manage memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ec679",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = None  # reset vector store\n",
    "question = 'How many companies are there?'\n",
    "test_state = {\n",
    "'objects_documentation':objects_documentation,\n",
    "'database_content':database_content,\n",
    "'sql_dialect': sql_dialect,\n",
    "'messages_log':[],\n",
    "'intermediate_steps' : [],\n",
    "'analytical_intent': [],\n",
    "'current_question':question,\n",
    "'current_sql_queries': [],\n",
    "'generate_answer_details': {},\n",
    "'llm_answer': AIMessage(content='')\n",
    "}\n",
    "orchestrator(test_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bb4e0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📣 Final Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_state = run_control_flow(test_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "67585d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue the conversation\n",
    "test_state['current_question'] = 'Yep, I would like to see how these ratings changed over time per company'\n",
    "test_state['intermediate_steps'] = []\n",
    "test_state['current_sql_queries'] = []\n",
    "test_state['generate_answer_details'] = {}\n",
    "test_state['analytical_intent'] = []\n",
    "test_state['llm_answer'] = AIMessage(content='')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "951c4e1ccc8e7dc066b7b3456b4d29f8a6c8c8949bd81a565897b5da2568416e"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
