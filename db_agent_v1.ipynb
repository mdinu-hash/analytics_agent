{"cells":[{"cell_type":"markdown","metadata":{"id":"590F0KaCNnLI"},"source":["### Import feedbacks.db file"]},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":true,"executionInfo":{"elapsed":3136,"status":"ok","timestamp":1745651582799,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"rTcnvPIOnsMt"},"outputs":[],"source":["# test access to db file: import db tables into data frames and select by the column names\n","\n","import pandas as pd\n","import sqlite3\n","from sqlalchemy import create_engine, inspect\n","\n","engine = create_engine('sqlite:///feedbacks_db.db')\n","inspector = inspect(engine)\n","\n","df_company = pd.read_sql_query('SELECT company_name,annual_revenue_usd FROM company', engine)\n","df_feedback = pd.read_sql_query('SELECT feedback_id,feedback_date,product_id,product_company_name,feedback_text,\"feedback_rating\" FROM feedback', engine)\n","df_products = pd.read_sql_query('SELECT product_id,product_name,product_brand,product_manufacturer,product_company_name,product_price,product_average_rating FROM products', engine)"]},{"cell_type":"markdown","metadata":{"id":"aktkTiDQOb-a"},"source":["### Instantiate chat model (OpenAI)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":9876,"status":"ok","timestamp":1745651667006,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"YZ4WXurxNm4l","outputId":"ddca8852-2d4a-48b1-9931-08d4490dc6c7"},"outputs":[],"source":["import langchain, langgraph, langchain_openai\n","\n","import os\n","from dotenv import load_dotenv\n","\n","load_dotenv()\n","openai_api_key = openai_api_key = os.getenv('OPENAI_API_KEY')\n","os.environ['OPENAI_API_KEY'] = openai_api_key\n","\n","from langchain_openai import ChatOpenAI\n","llm = ChatOpenAI(model='gpt-4o',temperature=0)"]},{"cell_type":"markdown","metadata":{"id":"3IFkVYMsw5h6"},"source":["### Define the test state for debugging and constants"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1745651668945,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"g5MghA2p18nk"},"outputs":[],"source":["# constants\n","question = 'What can you tell me about the dataset?'"]},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":true,"executionInfo":{"elapsed":27,"status":"ok","timestamp":1745651668975,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"3skCvKHyw4LE"},"outputs":[],"source":["# empty test_state\n","test_state = {'question':'',\n","              'sql_query':[],\n","              'sql_query_explanation':[],\n","              'sql_query_result':[],\n","              'llm_answer':[]\n","              }\n","\n","# function to initialize the state with the question\n","def add_question_test_state(question:str):\n"," test_state['question'] = question\n","\n","add_question_test_state(question)"]},{"cell_type":"markdown","metadata":{"id":"q9yns7F1Ope2"},"source":["### Create a function that generates the sql query to be executed"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":48,"status":"ok","timestamp":1745651670711,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"5i8XrQ1j6csG"},"outputs":[],"source":["objects_documentation = \"\"\"\n","  Table company: List of public companies. Granularity is company-name. Column (prefixed with table name):\n","  company.company-name: the name of the public company.\n","  company.annual_revenue_usd: revenue in last 12 months ($).\n","\n","  Table feedback: Feedbacks given by clients to products. Granularity is feedback. Key is feedback_id. Columns (prefixed with table name):\n","  feedback.feedback_id: id of the feedback.\n","  feedback.feedback_date: date of feedback.\n","  feedback.product_id: id of the product the feedback was given for.\n","  feedback.product_company_name: company owning the product.\n","  feedback.feedback_text: the text of the feedback.\n","  feedback.feedback_rating: rating of the feedback from 1 to 5, 5 being the highest score.\n","\n","  Table products: Shows product metadata. Granularity is product. Key is product_id. Columns (prefixed with table name):\n","  products.product_id: id of the product.\n","  products.product_name: name of the product.\n","  products.product_brand: the brand under which the product was presented.\n","  products.product_manufacturer: product manufacturer.\n","  products.product_company_name: company owning the product.\n","  products.product_price: price of the product at crawling time.\n","  products.product_average-rating: average ratings across all feedbacks for the product, at crawling time.\n","\n","  Table company -> column company_name relates to table feedback -> column product_company_name\n","  Table products -> column product_company_name relates to table feedback -> column product_company-name\n","  Table feedback -> column product_id relates to table products -> column product_id\n","  \"\"\""]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1745651670767,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"9e7vebzhljeX"},"outputs":[],"source":["# create a function that generates the sql query to be executed\n","\n","\n","# https://python.langchain.com/docs/concepts/prompt_templates/\n","# API reference: https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html\n","\n","from typing_extensions import TypedDict, Annotated\n","from langchain_core.prompts import PromptTemplate\n","\n","# define the state of the graph, which includes user's question, AI's answer, query that has been created and its result;\n","class State(TypedDict):\n"," question: str\n"," sql_query: list[str]\n"," sql_query_explanation : list[str]\n"," sql_query_result: list[str]\n"," llm_answer: str\n","\n","class OutputAsAQuery(TypedDict):\n","  \"\"\" generated sql query or sql queries if there are multiple \"\"\"\n","  query: Annotated[list[str],\"clean sql query\"]\n","\n","def create_sql_query_or_queries(state:State):\n","  \"\"\" creates a sql query based on the question \"\"\"\n","\n","  query_prompt_template_string = \"\"\"You are a sql expert and an expert data modeler.\n","\n","  You have access to the following tables and columns:\n","  {objects_documentation}\n","\n","  Using only the objects you have access to, create a sql script to answer the following question:\n","  {question}\n","\n","  Answer just with the resulting sql code.\n","\n","  IMPORTANT:\n","    - Return only raw SQL strings in the list.\n","    - DO NOT include comments (like \"-- Query 1\"), labels, or explanations.\n","    - If only one SQL query is needed, just return a list with that one query.\n","    - Do not generate more than 5 queries.\n","\n","  Example output:\n","    [\n","      \"SELECT COUNT(*) FROM feedback;\",\n","      \"SELECT AVG(product_price) FROM products;\"\n","    ]\n","  \"\"\"\n","\n","  query_prompt_template = PromptTemplate.from_template(query_prompt_template_string)\n","\n","  chain = (query_prompt_template\n","          | llm.with_structured_output(OutputAsAQuery)\n","          | (lambda output: {'sql_query':output['query']} # make default value of iterations to zero\n","        )  )\n","\n","  return chain.invoke({'objects_documentation':objects_documentation, 'question': state['question']})"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3105,"status":"ok","timestamp":1745651673875,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"uZLcJFI42Iha"},"outputs":[],"source":["# update test_state for debug\n","\n","test_state.update(create_sql_query_or_queries(test_state))\n","#test_state"]},{"cell_type":"markdown","metadata":{"id":"9M8JLe_FOyVS"},"source":["### create a function that executes the sql query"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1745651681382,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"5UvSQEg4fBqh"},"outputs":[],"source":["# since gpt-4o allows a maximum completion limit (output context limit) of 4k tokens, I half it to get maximum context size, so 2k. Assuming the entire context is not just the data,\n","# I divide this number by 5 and arrive at a limit of 400 tokens for the result of the sql query.\n","\n","import tiktoken\n","\n","maximum_nr_tokens_sql_query = 200\n","\n","# create a function that counts the tokens from a string\n","def count_tokens(string:str):\n"," \"\"\" returns the number of tokens in a text string \"\"\"\n"," encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n"," num_tokens = len(encoding.encode(string))\n"," return num_tokens\n","\n","# create a function that compares the tokens from the sql query result with the maximum token limit, and returns true if the context limit has been exceeded, false otherwise.\n","def check_if_exceed_maximum_context_limit(sql_query_result):\n"," \"\"\" compares the tokens from the sql query result with the maximum token limit, and returns true if the context limit has been exceeded, false otherwise \"\"\"\n"," tokens_sql_query_result = count_tokens(sql_query_result)\n"," if tokens_sql_query_result > maximum_nr_tokens_sql_query:\n","  return True\n"," else:\n","  return False\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1745651695813,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"w4RX85nF2FYD"},"outputs":[],"source":["# create a function that creates an explanation of a sql query\n","\n","def create_sql_query_explanation(sql_query:str):\n"," \"\"\" creates a concise explanation of the sql query \"\"\"\n","\n"," prompt_template = PromptTemplate.from_template(\"\"\"\n"," As a data expert, you are provided with this sql query:\n"," {sql_query}\n","\n"," Create a brief explanation of this query in simple terms by taking into account these factors, if exist:\n"," - Pay attention to the nuances of the query: the filters, aggregations, groupings, etc.\n"," - Take into account underlying assumptions.\n"," - Query limitations.\n"," Keep it short.\n"," \"\"\")\n","\n"," chain = prompt_template | llm\n"," sql_query_explanation = chain.invoke({'sql_query':sql_query}).content\n"," return sql_query_explanation"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1745651695864,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"SBP5z-Iwd5uQ"},"outputs":[],"source":["class OutputAsASingleQuery(TypedDict):\n","  \"\"\" generated sql query \"\"\"\n","  query: Annotated[str,...,\"the generated sql query\"]\n","\n","def refine_sql_query(question: str, sql_query: str, maximum_nr_tokens_sql_query: int):\n"," \"\"\" refines the sql query so that its output tokens do not exceed the maximum context limit \"\"\"\n","\n"," query_prompt_template_string = \"\"\"\n"," You are a sql expert an an expert data modeler.\n","\n"," You are tying to answer the following question from the user:\n"," {question}\n","\n"," The following sql query produces an output that exceeds {maximum_nr_tokens_sql_query} tokens:\n"," {sql_query}\n","\n"," Please optimize this query so that its output stays within the token limit while still providing as much insight as possible to answer the question.\n"," Prefer using WHERE or LIMIT clauses to reduce the size of the result.\n"," \"\"\"\n"," sys_prompt_template = PromptTemplate.from_template(query_prompt_template_string)\n","\n"," chain = (sys_prompt_template\n","         | llm.with_structured_output(OutputAsASingleQuery)\n"," )\n","\n"," sql_query = chain.invoke({'question': question,\n","               'sql_query':sql_query,\n","               'maximum_nr_tokens_sql_query':maximum_nr_tokens_sql_query})\n"," return sql_query"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1745656992128,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"8cRD7m7Q-9NF"},"outputs":[],"source":["# the function checks if the query output exceeds context window limit and if yes, send the query for refinement\n","\n","from langchain_community.tools import QuerySQLDataBaseTool\n","from langchain_community.utilities import SQLDatabase\n","from typing import Iterator\n","\n","db = SQLDatabase(engine)\n","\n","def execute_sql_query(state:State):\n","  \"\"\" executes the sql query and retrieve the result \"\"\"\n","\n","  for query_index, sql_query in enumerate(state['sql_query']):\n","\n","    print(f\"üöÄ Executing query {query_index+1}/{len(state['sql_query'])}...\")\n","    # refine the query 3 times if necessary.\n","    for i in range(3):\n","\n","      sql_query_result = QuerySQLDataBaseTool(db=db).invoke(sql_query)\n","\n","      # if the sql query does not exceed output context window return its result\n","      if not check_if_exceed_maximum_context_limit(sql_query_result):\n","\n","       sql_query_explanation = create_sql_query_explanation(sql_query)\n","       state['sql_query_result'].append(sql_query_result)\n","       state['sql_query_explanation'].append(sql_query_explanation)\n","       break\n","\n","      # if the sql query exceeds output context window and there is more room for iterations, refine the query\n","      else:\n","        print(f\"üîß Refining query {query_index+1}/{len(state['sql_query'])} as its output its too large...\")\n","        sql_query = refine_sql_query(state['question'],sql_query,maximum_nr_tokens_sql_query)['query']\n","\n","      # if there is no more room for sql query iterations and the result still exceeds context window, throw a message\n","\n","    else:\n","      print(f\"‚ö†Ô∏è Query result too large after 3 refinements.\")\n","      state['sql_query_result'].append('Query result too large after 3 refinements.')\n","      state['sql_query_explanation'].append(\"Refinement failed.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"vQvoPE4-ZEgs"},"outputs":[],"source":["# update test_state for debug\n","execute_sql_query(test_state)\n","#test_state"]},{"cell_type":"markdown","metadata":{"id":"cGrig_oyFiYs"},"source":["### Extract metadata from sql query"]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":true,"executionInfo":{"elapsed":29,"status":"ok","timestamp":1745651788371,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"szswa3o2WftH"},"outputs":[],"source":["import sqlglot\n","from sqlglot import parse_one, exp\n","\n","def extract_metadata_from_sql_query(sql_query):\n"," ast = parse_one(sql_query)\n","\n"," sql_query_metadata = {\n","    \"tables\": [],\n","    \"filters\": [],\n","    \"aggregations\": [],\n","    \"groupings\": []\n"," }\n","\n"," # extract tables\n"," table_generator = ast.find_all(sqlglot.expressions.Table)\n"," for items in table_generator:\n","    sql_query_metadata['tables'].append(items.sql())\n"," # remove dups\n"," sql_query_metadata['tables'] = list(dict.fromkeys(sql_query_metadata['tables']))\n","\n"," # extract filters\n"," where_conditions = ast.find_all(sqlglot.expressions.Where)\n"," for item in where_conditions:\n","  sql_query_metadata['filters'].append(item.this.sql())\n","  # remove dups\n"," sql_query_metadata['filters'] = list(dict.fromkeys(sql_query_metadata['filters']))\n","\n"," # extract aggregate functions\n"," funcs = ast.find_all(sqlglot.expressions.AggFunc)\n"," for item in funcs:\n","  sql_query_metadata['aggregations'].append(item.sql())\n"," # remove dups\n"," sql_query_metadata['aggregations'] = list(dict.fromkeys(sql_query_metadata['aggregations']))\n","\n"," # extract groupings\n"," groupings = ast.find_all(sqlglot.expressions.Group)\n"," for item in groupings:\n","  groupings_flattened = item.flatten()\n","  for item in groupings_flattened:\n","    sql_query_metadata['groupings'].append(item.sql())\n"," # remove dups\n"," sql_query_metadata['groupings'] = list(dict.fromkeys(sql_query_metadata['groupings']))\n","\n"," return sql_query_metadata"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1745651788376,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"gtVG4RRs6rWD"},"outputs":[],"source":["# test it:\n","#sql_query = test_state['sql_query'][0]\n","#extract_metadata_from_sql_query(sql_query)"]},{"cell_type":"markdown","metadata":{"id":"LOsY-ugvxH2c"},"source":["### create_explanation"]},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":true,"executionInfo":{"elapsed":61,"status":"ok","timestamp":1745651799789,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"gUDPtp0BoHHO"},"outputs":[],"source":["def create_explanation(sql_queries: list[str]):\n"," \"\"\" based on the sql query metadata that was parsed, it creates a natural language message describing filters and transformations used by the query\"\"\"\n","\n"," tables = []\n"," filters = []\n"," aggregations = []\n"," groupings = []\n","\n"," for item in sql_queries:\n"," # get sql query metadata\n","  sql_query = item\n","  sql_query_metadata = extract_metadata_from_sql_query(sql_query)\n","\n","  if sql_query_metadata['tables']:\n","   tables.extend(sql_query_metadata['tables'])\n","   tables = list(dict.fromkeys(tables))\n","\n","  if sql_query_metadata['filters']:\n","   filters.extend(sql_query_metadata['filters'])\n","   filters = list(dict.fromkeys(filters))\n","\n","  if sql_query_metadata['aggregations']:\n","   aggregations.extend(sql_query_metadata['aggregations'])\n","   aggregations = list(dict.fromkeys(aggregations))\n","\n","  if sql_query_metadata['groupings']:\n","   groupings.extend(sql_query_metadata['groupings'])\n","   groupings = list(dict.fromkeys(groupings))\n","\n"," # wrapping it all together\n"," sql_query_explanation = \"I analyzed data based on the following filters and transformations:\"\n","\n"," if tables:\n","  tables = f\"üßä Tables: ‚Ä¢ {' ‚Ä¢ '.join(tables)}\"\n","  sql_query_explanation = sql_query_explanation + \"\\n\\n\" + tables\n","\n"," if filters:\n","  filters = f\"üîç Filters: ‚Ä¢ {' ‚Ä¢ '.join(filters)}\"\n","  sql_query_explanation = sql_query_explanation + \"\\n\\n\" + filters\n","\n"," if aggregations:\n","  aggregations = f\"üßÆ Aggregations: ‚Ä¢ {' ‚Ä¢ '.join(aggregations)}\"\n","  sql_query_explanation = sql_query_explanation + \"\\n\\n\" + aggregations\n","\n"," if groupings:\n","  groupings = f\"üì¶ Groupings: ‚Ä¢ {' ‚Ä¢ '.join(groupings)}\"\n","  sql_query_explanation = sql_query_explanation + \"\\n\\n\" + groupings\n","\n"," return sql_query_explanation"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1745651799793,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"e-wQeNeruBuR"},"outputs":[],"source":["# test it\n","#print(create_explanation(test_state['sql_query']))"]},{"cell_type":"markdown","metadata":{"id":"TlLMbl7oO7jo"},"source":["### create a function that generates the agent answer based on sql query result"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1745651801887,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"Te4lyaKbp8DZ"},"outputs":[],"source":["## create a function that generates the agent answer based on sql query result\n","\n","def generate_answer(state:State):\n","  \"\"\" generates the AI answer taking into consideration the explanation and the result of the sql query that was executed \"\"\"\n","\n","  prompt_template = PromptTemplate.from_template(\n","     \"\"\" You are a decision support consultant helping users become more data-driven.\n","     Your task is to answer the user question based on the following information:\n","\n","     - The sql query result which is the result of a query created for the purpose of answering the question.\n","     - The query explanation is a short explanation of the query making you aware of its limitations and underlying assumptions.\n","\n","    User question:\n","    {question}\n","\n","    SQL query explanation:\n","    {sql_query_explanation}\n","\n","    SQL query result:\n","    {sql_query_result}\n","\n","    Take into account the insights from this explanation in your answer.\n","    Answer in simple terms, conversational, non-technical language. Be concise.\n","    \"\"\")\n","\n","  chain = (prompt_template\n","        | llm\n","        | (lambda output: {'llm_answer': f\"{output.content}\\n\\n{create_explanation(state['sql_query'])}\"})\n","  )\n","\n","  return chain.invoke({'question':state['question'],\n","                     'sql_query_explanation':state['sql_query_explanation'],\n","                     'sql_query_result':state['sql_query_result']})"]},{"cell_type":"code","execution_count":19,"metadata":{"collapsed":true,"executionInfo":{"elapsed":5576,"status":"ok","timestamp":1745651807466,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"jh8M_xens_rR"},"outputs":[],"source":["# test the function\n","test_state.update(generate_answer(test_state))\n","#test_state"]},{"cell_type":"markdown","metadata":{"id":"WFFhFgT2PDH9"},"source":["### assemble the graph"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1745656995421,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"tWQdCVSjHrKO"},"outputs":[],"source":["# assemble graph\n","\n","from langgraph.graph import StateGraph, START, END\n","\n","graph= StateGraph(State)\n","graph.add_node(\"create_sql_query_or_queries\",create_sql_query_or_queries)\n","graph.add_node(\"execute_sql_query\",execute_sql_query)\n","graph.add_node(\"generate_answer\",generate_answer)\n","\n","graph.add_edge(START,\"create_sql_query_or_queries\")\n","graph.add_edge(\"create_sql_query_or_queries\",\"execute_sql_query\")\n","graph.add_edge(\"execute_sql_query\",\"generate_answer\")\n","graph.add_edge(\"generate_answer\",END)\n","graph = graph.compile()"]},{"cell_type":"markdown","metadata":{"id":"GBxFV-aePGIw"},"source":["### test the agent"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":24556,"status":"ok","timestamp":1745657021519,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"XT-hREYWN_Jf","outputId":"181fe769-7581-46c8-be1a-c69a660f34f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ SQL queries created:5\n","üöÄ Executing query 1/5...\n","üöÄ Executing query 2/5...\n","üöÄ Executing query 3/5...\n","üöÄ Executing query 4/5...\n","üöÄ Executing query 5/5...\n","‚öôÔ∏è Analysing results...\n","\n","üì£ Final Answer:\n","\n","The dataset includes information about companies, feedback, and products. Here's a quick overview:\n","\n","1. **Companies**: There are 12 unique company names in the dataset. This means there are 12 different companies listed.\n","\n","2. **Feedback**: There are 413,898 unique feedback entries. This is a large number, indicating a lot of feedback data is available.\n","\n","3. **Products**: There are 8,145 unique products. This suggests a wide variety of products are included in the dataset.\n","\n","4. **Feedback Ratings**: The average feedback rating is about 3.84. This gives a general idea of how users feel about the products or services.\n","\n","5. **Product Prices**: The average price of the products is approximately 158.87. This provides a sense of the typical cost of products in the dataset.\n","\n","Overall, the dataset is quite comprehensive, covering a range of companies, feedback, and products, with insights into average ratings and prices.\n","\n","I analyzed data based on the following filters and transformations:\n","\n","üßä Tables: ‚Ä¢ company ‚Ä¢ feedback ‚Ä¢ products\n","\n","üßÆ Aggregations: ‚Ä¢ COUNT(DISTINCT company.company_name) ‚Ä¢ COUNT(DISTINCT feedback.feedback_id) ‚Ä¢ COUNT(DISTINCT products.product_id) ‚Ä¢ AVG(feedback.feedback_rating) ‚Ä¢ AVG(products.product_price)\n"]}],"source":["initial_dict = {'objects_documentation':objects_documentation,\n","     'question':question,\n","     'sql_query': [],\n","     'sql_query_result': [],\n","     'sql_query_explanation': [],\n","     'llm_answer': ''\n","     }\n","\n","for step in graph.stream(initial_dict, stream_mode=\"updates\"):\n","  step_name, output = list(step.items())[0]\n","  if step_name == 'create_sql_query_or_queries':\n","    print(f\"‚úÖ SQL queries created:{len(output['sql_query'])}\")\n","  elif step_name == 'execute_sql_query':\n","    print(\"‚öôÔ∏è Analysing results...\")\n","  elif step_name == 'generate_answer':\n","    print(\"\\nüì£ Final Answer:\\n\")\n","    print(output['llm_answer'])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPXPMNTeyikjHOE73oHocjZ","collapsed_sections":["590F0KaCNnLI","aktkTiDQOb-a","3IFkVYMsw5h6","q9yns7F1Ope2","9M8JLe_FOyVS","cGrig_oyFiYs","LOsY-ugvxH2c","TlLMbl7oO7jo","WFFhFgT2PDH9","GBxFV-aePGIw"],"provenance":[]},"interpreter":{"hash":"951c4e1ccc8e7dc066b7b3456b4d29f8a6c8c8949bd81a565897b5da2568416e"},"kernelspec":{"display_name":"Python 3.9.13 ('.venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
