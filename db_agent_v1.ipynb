{"cells":[{"cell_type":"markdown","metadata":{"id":"590F0KaCNnLI"},"source":["### Import feedbacks.db file"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"executionInfo":{"elapsed":3136,"status":"ok","timestamp":1745651582799,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"rTcnvPIOnsMt"},"outputs":[],"source":["# test access to db file: import db tables into data frames and select by the column names\n","\n","import pandas as pd\n","import sqlite3\n","from sqlalchemy import create_engine, inspect\n","\n","engine = create_engine('sqlite:///feedbacks_db.db')\n","inspector = inspect(engine)\n","\n","df_company = pd.read_sql_query('SELECT company_name,annual_revenue_usd FROM company', engine)\n","df_feedback = pd.read_sql_query('SELECT feedback_id,feedback_date,product_id,product_company_name,feedback_text,\"feedback_rating\" FROM feedback', engine)\n","df_products = pd.read_sql_query('SELECT product_id,product_name,product_brand,product_manufacturer,product_company_name,product_price,product_average_rating FROM products', engine)"]},{"cell_type":"markdown","metadata":{"id":"aktkTiDQOb-a"},"source":["### Instantiate chat model (OpenAI)"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":9876,"status":"ok","timestamp":1745651667006,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"YZ4WXurxNm4l","outputId":"ddca8852-2d4a-48b1-9931-08d4490dc6c7"},"outputs":[],"source":["import langchain, langgraph, langchain_openai, langsmith\n","\n","import os\n","from dotenv import load_dotenv\n","from langchain_core.runnables import RunnableConfig\n","from langchain.callbacks.tracers.langchain import LangChainTracer\n","\n","load_dotenv(override=True)\n","openai_api_key = os.getenv('OPENAI_API_KEY')\n","LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n","os.environ['OPENAI_API_KEY'] = openai_api_key\n","os.environ['LANGSMITH_API_KEY'] = LANGSMITH_API_KEY\n","os.environ['LANGSMITH_TRACING'] = \"true\"\n","os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n","langsmith_project_name = \"db_agent_v1\"\n","os.environ['LANGSMITH_PROJECT'] = langsmith_project_name\n","\n","# Set up LangSmith tracer manually\n","tracer = LangChainTracer(project_name=langsmith_project_name)\n","\n","from langchain_openai import ChatOpenAI\n","llm = ChatOpenAI(model='gpt-4o',temperature=0)"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["# config function for tracing in langsmith\n","import datetime\n","\n","def create_config(run_name):\n","    time_now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n","    run_name = f\"{run_name} {time_now}\"\n","    config={'callbacks':[tracer], 'run_name': run_name}\n","    return config\n","\n","# use it like so:\n","# run_name = 'create_sql_query_or_queries'\n","# create_config(run_name)\n","# chain.invoke({},config = create_config('test_prompt2'))\n","# every run name contains the current date time\n"]},{"cell_type":"markdown","metadata":{},"source":["### Constants"]},{"cell_type":"code","execution_count":70,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1745651668945,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"g5MghA2p18nk"},"outputs":[],"source":["# constants\n","\n","objects_documentation = \"\"\"\n","  Table company: List of public companies. Granularity is company-name. Column (prefixed with table name):\n","  company.company-name: the name of the public company.\n","  company.annual_revenue_usd: revenue in last 12 months ($).\n","\n","  Table feedback: Feedbacks given by clients to products. Granularity is feedback. Key is feedback_id. Columns (prefixed with table name):\n","  feedback.feedback_id: id of the feedback.\n","  feedback.feedback_date: date of feedback.\n","  feedback.product_id: id of the product the feedback was given for.\n","  feedback.product_company_name: company owning the product.\n","  feedback.feedback_text: the text of the feedback.\n","  feedback.feedback_rating: rating of the feedback from 1 to 5, 5 being the highest score.\n","\n","  Table products: Shows product metadata. Granularity is product. Key is product_id. Columns (prefixed with table name):\n","  products.product_id: id of the product.\n","  products.product_name: name of the product.\n","  products.product_brand: the brand under which the product was presented.\n","  products.product_manufacturer: product manufacturer.\n","  products.product_company_name: company owning the product.\n","  products.product_price: price of the product at crawling time.\n","  products.product_average-rating: average ratings across all feedbacks for the product, at crawling time.\n","\n","  Table company -> column company_name relates to table feedback -> column product_company_name\n","  Table products -> column product_company_name relates to table feedback -> column product_company-name\n","  Table feedback -> column product_id relates to table products -> column product_id\n","  \"\"\"\n","  \n","question = 'What can you tell me about the dataset?'"]},{"cell_type":"markdown","metadata":{},"source":["### State of the graph"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["# define the state of the graph, which includes user's question, AI's answer, query that has been created and its result;\n","from typing_extensions import TypedDict, Annotated\n","from langgraph.graph.message import add_messages\n","from typing import Sequence\n","from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, RemoveMessage\n","\n","\n","class State(TypedDict):\n"," messages_log: Sequence[BaseMessage]\n"," question: str\n"," sql_query: list[str]\n"," sql_query_explanation : list[str]\n"," sql_query_result: list[str]\n"," llm_answer: str"]},{"cell_type":"markdown","metadata":{"id":"3IFkVYMsw5h6"},"source":["### Test state for debugging"]},{"cell_type":"code","execution_count":36,"metadata":{"collapsed":true,"executionInfo":{"elapsed":27,"status":"ok","timestamp":1745651668975,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"3skCvKHyw4LE"},"outputs":[],"source":["# empty test_state\n","test_state = { 'messages_log' : [],\n","              'question':'',\n","              'sql_query':[],\n","              'sql_query_explanation':[],\n","              'sql_query_result':[],\n","              'llm_answer':[]\n","              }\n","\n","# function to initialize the state with the question\n","def add_question_test_state(question:str):\n"," test_state['question'] = question\n","\n","#add_question_test_state(question)"]},{"cell_type":"markdown","metadata":{"id":"q9yns7F1Ope2"},"source":["### Generates the sql query"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1745651670767,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"9e7vebzhljeX"},"outputs":[],"source":["# create a function that generates the sql query to be executed\n","\n","\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","class OutputAsAQuery(TypedDict):\n","  \"\"\" generated sql query or sql queries if there are multiple \"\"\"\n","  query: Annotated[list[str],\"clean sql query\"]\n","\n","def create_sql_query_or_queries(state:State):\n","  \"\"\" creates a sql query based on the question \"\"\"\n","\n","  system_prompt = \"\"\"You are a sql expert and an expert data modeler.  \n","\n","  Your task is to create a sql script to answer the user's question. In the sql script, use only these tables and columns you have access to:\n","  {objects_documentation}\n","\n","  User question:\n","  {question}\n","\n","  Answer just with the resulting sql code.\n","\n","  IMPORTANT:\n","    - Return only raw SQL strings in the list.\n","    - DO NOT include comments (like \"-- Query 1\"), labels, or explanations.\n","    - If only one SQL query is needed, just return a list with that one query.\n","    - Do not generate more than 5 queries.\n","\n","  Example output:\n","    [\n","      \"SELECT COUNT(*) FROM feedback;\",\n","      \"SELECT AVG(product_price) FROM products;\"\n","    ]\n","  \"\"\"\n","\n","  prompt = ChatPromptTemplate.from_messages(\n","    ('system', system_prompt)\n","  )\n","\n","  chain = (prompt\n","          | llm.with_structured_output(OutputAsAQuery)\n","          | (lambda output: {'sql_query':output['query']} \n","        )  )\n","\n","  return chain.invoke({'objects_documentation':objects_documentation, 'question': state['question']},config = create_config('create_sql_query_or_queries'))"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":3105,"status":"ok","timestamp":1745651673875,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"uZLcJFI42Iha"},"outputs":[],"source":["# update test_state for debug\n","\n","test_state.update(create_sql_query_or_queries(test_state))\n","#test_state"]},{"cell_type":"markdown","metadata":{"id":"9M8JLe_FOyVS"},"source":["### Executes the sql query"]},{"cell_type":"code","execution_count":73,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1745651681382,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"5UvSQEg4fBqh"},"outputs":[],"source":["# since gpt-4o allows a maximum completion limit (output context limit) of 4k tokens, I half it to get maximum context size, so 2k. Assuming the entire context is not just the data,\n","# I divide this number by 5 and arrive at a limit of 400 tokens for the result of the sql query.\n","\n","import tiktoken\n","\n","maximum_nr_tokens_sql_query = 200\n","\n","# create a function that counts the tokens from a string\n","def count_tokens(string:str):\n"," \"\"\" returns the number of tokens in a text string \"\"\"\n"," encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n"," num_tokens = len(encoding.encode(string))\n"," return num_tokens\n","\n","# create a function that compares the tokens from the sql query result with the maximum token limit, and returns true if the context limit has been exceeded, false otherwise.\n","def check_if_exceed_maximum_context_limit(sql_query_result):\n"," \"\"\" compares the tokens from the sql query result with the maximum token limit, and returns true if the context limit has been exceeded, false otherwise \"\"\"\n"," tokens_sql_query_result = count_tokens(sql_query_result)\n"," if tokens_sql_query_result > maximum_nr_tokens_sql_query:\n","  return True\n"," else:\n","  return False\n"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1745651695813,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"w4RX85nF2FYD"},"outputs":[],"source":["# create a function that creates an explanation of a sql query\n","\n","def create_sql_query_explanation(sql_query:str):\n"," \"\"\" creates a concise explanation of the sql query \"\"\"\n","\n"," system_prompt = \"\"\"\n"," As a data expert, you are provided with this sql query:\n"," {sql_query}\n","\n"," Create a brief explanation of this query in simple terms by taking into account these factors, if exist:\n"," - Pay attention to the nuances of the query: the filters, aggregations, groupings, etc.\n"," - Take into account underlying assumptions.\n"," - Query limitations.\n"," Keep it short.\n"," \"\"\"\n","\n"," prompt = ChatPromptTemplate.from_messages(\n","     ('system',system_prompt)\n"," )\n","\n"," chain = prompt | llm\n"," sql_query_explanation = chain.invoke({'sql_query':sql_query},config = create_config('create_sql_query_explanation')).content\n"," return sql_query_explanation"]},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1745651695864,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"SBP5z-Iwd5uQ"},"outputs":[],"source":["class OutputAsASingleQuery(TypedDict):\n","  \"\"\" generated sql query \"\"\"\n","  query: Annotated[str,...,\"the generated sql query\"]\n","\n","def refine_sql_query(question: str, sql_query: str, maximum_nr_tokens_sql_query: int):\n"," \"\"\" refines the sql query so that its output tokens do not exceed the maximum context limit \"\"\"\n","\n"," system_prompt = \"\"\"\n"," You are a sql expert an an expert data modeler.\n","\n"," You are tying to answer the following question from the user:\n"," {question}\n","\n"," The following sql query produces an output that exceeds {maximum_nr_tokens_sql_query} tokens:\n"," {sql_query}\n","\n"," Please optimize this query so that its output stays within the token limit while still providing as much insight as possible to answer the question.\n"," Prefer using WHERE or LIMIT clauses to reduce the size of the result.\n"," \"\"\"\n"," \n"," prompt = ChatPromptTemplate.from_messages(\n","   ('system',system_prompt)\n"," )\n","\n"," chain = (prompt\n","         | llm.with_structured_output(OutputAsASingleQuery)\n"," )\n","\n"," sql_query = chain.invoke({'question': question,\n","               'sql_query':sql_query,\n","               'maximum_nr_tokens_sql_query':maximum_nr_tokens_sql_query}\n","               ,create_config('refine_sql_query'))\n"," return sql_query"]},{"cell_type":"code","execution_count":76,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1745656992128,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"8cRD7m7Q-9NF"},"outputs":[],"source":["# the function checks if the query output exceeds context window limit and if yes, send the query for refinement\n","\n","from langchain_community.tools import QuerySQLDataBaseTool\n","from langchain_community.utilities import SQLDatabase\n","from typing import Iterator\n","\n","db = SQLDatabase(engine)\n","\n","def execute_sql_query(state:State):\n","  \"\"\" executes the sql query and retrieve the result \"\"\"\n","\n","  for query_index, sql_query in enumerate(state['sql_query']):\n","\n","    print(f\"üöÄ Executing query {query_index+1}/{len(state['sql_query'])}...\")\n","    # refine the query 3 times if necessary.\n","    for i in range(3):\n","\n","      sql_query_result = QuerySQLDataBaseTool(db=db).invoke(sql_query)\n","\n","      # if the sql query does not exceed output context window return its result\n","      if not check_if_exceed_maximum_context_limit(sql_query_result):\n","\n","       sql_query_explanation = create_sql_query_explanation(sql_query)\n","       state['sql_query_result'].append(sql_query_result)\n","       state['sql_query_explanation'].append(sql_query_explanation)\n","       break\n","\n","      # if the sql query exceeds output context window and there is more room for iterations, refine the query\n","      else:\n","        print(f\"üîß Refining query {query_index+1}/{len(state['sql_query'])} as its output its too large...\")\n","        sql_query = refine_sql_query(state['question'],sql_query,maximum_nr_tokens_sql_query)['query']\n","\n","      # if there is no more room for sql query iterations and the result still exceeds context window, throw a message\n","\n","    else:\n","      print(f\"‚ö†Ô∏è Query result too large after 3 refinements.\")\n","      state['sql_query_result'].append('Query result too large after 3 refinements.')\n","      state['sql_query_explanation'].append(\"Refinement failed.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"vQvoPE4-ZEgs"},"outputs":[],"source":["# update test_state for debug\n","execute_sql_query(test_state)\n","#test_state"]},{"cell_type":"markdown","metadata":{"id":"cGrig_oyFiYs"},"source":["### Extract metadata from sql query"]},{"cell_type":"code","execution_count":77,"metadata":{"collapsed":true,"executionInfo":{"elapsed":29,"status":"ok","timestamp":1745651788371,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"szswa3o2WftH"},"outputs":[],"source":["import sqlglot\n","from sqlglot import parse_one, exp\n","\n","def extract_metadata_from_sql_query(sql_query):\n"," ast = parse_one(sql_query)\n","\n"," sql_query_metadata = {\n","    \"tables\": [],\n","    \"filters\": [],\n","    \"aggregations\": [],\n","    \"groupings\": []\n"," }\n","\n"," # extract tables\n"," table_generator = ast.find_all(sqlglot.expressions.Table)\n"," for items in table_generator:\n","    sql_query_metadata['tables'].append(items.sql())\n"," # remove dups\n"," sql_query_metadata['tables'] = list(dict.fromkeys(sql_query_metadata['tables']))\n","\n"," # extract filters\n"," where_conditions = ast.find_all(sqlglot.expressions.Where)\n"," for item in where_conditions:\n","  sql_query_metadata['filters'].append(item.this.sql())\n","  # remove dups\n"," sql_query_metadata['filters'] = list(dict.fromkeys(sql_query_metadata['filters']))\n","\n"," # extract aggregate functions\n"," funcs = ast.find_all(sqlglot.expressions.AggFunc)\n"," for item in funcs:\n","  sql_query_metadata['aggregations'].append(item.sql())\n"," # remove dups\n"," sql_query_metadata['aggregations'] = list(dict.fromkeys(sql_query_metadata['aggregations']))\n","\n"," # extract groupings\n"," groupings = ast.find_all(sqlglot.expressions.Group)\n"," for item in groupings:\n","  groupings_flattened = item.flatten()\n","  for item in groupings_flattened:\n","    sql_query_metadata['groupings'].append(item.sql())\n"," # remove dups\n"," sql_query_metadata['groupings'] = list(dict.fromkeys(sql_query_metadata['groupings']))\n","\n"," return sql_query_metadata"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1745651788376,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"gtVG4RRs6rWD"},"outputs":[],"source":["# test it:\n","#sql_query = test_state['sql_query'][0]\n","#extract_metadata_from_sql_query(sql_query)"]},{"cell_type":"markdown","metadata":{"id":"LOsY-ugvxH2c"},"source":["### create explanation to show transparency over filters and transformations used"]},{"cell_type":"code","execution_count":78,"metadata":{"collapsed":true,"executionInfo":{"elapsed":61,"status":"ok","timestamp":1745651799789,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"gUDPtp0BoHHO"},"outputs":[],"source":["def create_explanation(sql_queries: list[str]):\n"," \"\"\" based on the sql query metadata that was parsed, it creates a natural language message describing filters and transformations used by the query\"\"\"\n","\n"," tables = []\n"," filters = []\n"," aggregations = []\n"," groupings = []\n","\n"," for item in sql_queries:\n"," # get sql query metadata\n","  sql_query = item\n","  sql_query_metadata = extract_metadata_from_sql_query(sql_query)\n","\n","  if sql_query_metadata['tables']:\n","   tables.extend(sql_query_metadata['tables'])\n","   tables = list(dict.fromkeys(tables))\n","\n","  if sql_query_metadata['filters']:\n","   filters.extend(sql_query_metadata['filters'])\n","   filters = list(dict.fromkeys(filters))\n","\n","  if sql_query_metadata['aggregations']:\n","   aggregations.extend(sql_query_metadata['aggregations'])\n","   aggregations = list(dict.fromkeys(aggregations))\n","\n","  if sql_query_metadata['groupings']:\n","   groupings.extend(sql_query_metadata['groupings'])\n","   groupings = list(dict.fromkeys(groupings))\n","\n"," # wrapping it all together\n"," sql_query_explanation = \"I analyzed data based on the following filters and transformations:\"\n","\n"," if tables:\n","  tables = f\"üßä Tables: ‚Ä¢ {' ‚Ä¢ '.join(tables)}\"\n","  sql_query_explanation = sql_query_explanation + \"\\n\\n\" + tables\n","\n"," if filters:\n","  filters = f\"üîç Filters: ‚Ä¢ {' ‚Ä¢ '.join(filters)}\"\n","  sql_query_explanation = sql_query_explanation + \"\\n\\n\" + filters\n","\n"," if aggregations:\n","  aggregations = f\"üßÆ Aggregations: ‚Ä¢ {' ‚Ä¢ '.join(aggregations)}\"\n","  sql_query_explanation = sql_query_explanation + \"\\n\\n\" + aggregations\n","\n"," if groupings:\n","  groupings = f\"üì¶ Groupings: ‚Ä¢ {' ‚Ä¢ '.join(groupings)}\"\n","  sql_query_explanation = sql_query_explanation + \"\\n\\n\" + groupings\n","\n"," return sql_query_explanation"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1745651799793,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"e-wQeNeruBuR"},"outputs":[],"source":["# test it\n","#print(create_explanation(test_state['sql_query']))"]},{"cell_type":"markdown","metadata":{},"source":["### Manage memory and chat history"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[],"source":["def manage_memory_chat_history(state:State):\n","    \"\"\" Manages the chat history so that it does not become too large in terms of output tokens.\n","    Specifically, it checks if the chat history is larger than 1000 tokens. If yes, keep just the last 2 pairs of human prompts and AI responses, and summarize the older messages.\n","    Additionally, check if the logs of sql queries is larger than 20 entries. If yes, delete the older records. \"\"\"\n","\n","    tokens_chat_history = state['messages_log'][-1].response_metadata['token_usage']['total_tokens']        \n","\n","    if tokens_chat_history >= 1000 and len(state['messages_log']) > 4:\n","        message_history_to_summarize = [msg.content for msg in state['messages_log'][:-4]]\n","        prompt = ChatPromptTemplate.from_messages( [('user', 'Distill the below chat messages into a single summary paragraph.The summary paragraph should have maximum 400 tokens.Include as many specific details as you can.Chat messages:{message_history_to_summarize}') ])\n","        runnable = prompt | llm\n","        chat_history_summary = runnable.invoke({'message_history_to_summarize':message_history_to_summarize},config = create_config('manage_memory_chat_history'))\n","        last_4_messages = state['messages_log'][-4:]\n","        last_user_question = HumanMessage(state['question'])\n","        #delete_messages = [RemoveMessage(id = msg.id) for msg in state['messages_log'][:-4]] # delete messages older than the last 4 \n","        state['messages_log'] = [chat_history_summary] +[*last_4_messages] + [last_user_question]  \n","\n","    # Optional: Truncate SQL logs to the most recent 20\n","    if len(state['sql_query']) > 20:\n","        state['sql_query'] = state['sql_query'][-20:]\n","        state['sql_query_explanation'] = state['sql_query_explanation'][-20:]\n","        state['sql_query_result'] = state['sql_query_result'][-20:]\n","\n","    return state"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["messages_log = [\n","    HumanMessage(content = 'How many companies are there?',id=1),\n","    AIMessage(content = '''üì£ Final Answer:\n","\n","There are 12 unique companies listed in the data. Keep in mind, though, that if there are any variations in how the company names are written (like different spellings or capitalization), it might affect the count slightly.\n","\n","I analyzed data based on the following filters and transformations:\n","\n","üßä Tables: ‚Ä¢ company\n","\n","üßÆ Aggregations: ‚Ä¢ COUNT(DISTINCT company.company_name)''',id=2),\n","\n","    HumanMessage(content = 'What can you tell me about the dataset?',id=3),\n","    AIMessage(content = '''üì£ Final Answer:\n","\n","The dataset provides some interesting insights:\n","\n","1. There are 12 unique companies listed in the dataset.\n","2. On average, these companies have an annual revenue of about $26.3 trillion USD.\n","3. There are 413,898 unique feedback entries, which means a lot of feedback has been collected.\n","4. The average feedback rating is approximately 3.84 out of a possible scale (not specified here).\n","5. There are 8,145 unique products in the dataset.\n","\n","These numbers give a broad overview of the dataset, showing a diverse range of companies, a significant amount of feedback, and a large variety of products. However, it doesn't dive into specifics like industry types, regional data, or detailed company attributes.\n","\n","I analyzed data based on the following filters and transformations:\n","\n","üßä Tables: ‚Ä¢ company ‚Ä¢ feedback ‚Ä¢ products\n","\n","üßÆ Aggregations: ‚Ä¢ COUNT(DISTINCT company.company_name) ‚Ä¢ AVG(company.annual_revenue_usd) ‚Ä¢ COUNT(DISTINCT feedback.feedback_id) ‚Ä¢ AVG(feedback.feedback_rating) ‚Ä¢ COUNT(DISTINCT products.product_id)',id=5),\n","    HumanMessage(content = 'tell me a joke about rum refering to my name''',id=4),\n","   \n","    HumanMessage(content = 'Can you share the average feedback rating per company?',id=5),\n","    AIMessage(content = '''üì£ Final Answer:\n","\n","Sure! Here's the average feedback rating for each company based on the data we have:\n","\n","- Adidas: 4.06\n","- Apple: 3.85\n","- AT&T: 3.66\n","- Cisco: 3.37\n","- Google: 3.56\n","- Microsoft: 3.91\n","- Nike: 3.95\n","- Samsung: 3.87\n","- Sony: 3.83\n","- Target: 3.33\n","- Verizon: 3.84\n","- Walmart: 3.31\n","\n","These numbers represent the average feedback ratings from customers for each company. Keep in mind that this is a straightforward average and doesn't account for things like the number of feedback entries or any unusual ratings that might affect the average.\n","\n","I analyzed data based on the following filters and transformations:\n","...\n","\n","üßÆ Aggregations: ‚Ä¢ AVG(feedback.feedback_rating)\n","\n","üì¶ Groupings: ‚Ä¢ feedback.product_company_name''',id=6),\n","    \n","    HumanMessage(content = 'fine, and how many products each company has?',id=7),\n","    AIMessage(content = '''üì£ Final Answer:\n","\n","Sure! Here's a quick rundown of how many products each company has:\n","\n","- Adidas has 181 products.\n","- Apple offers 1,178 products.\n","- AT&T has 134 products.\n","- Cisco has 9 products.\n","- Google has 459 products.\n","- Microsoft offers 75 products.\n","- Nike has 115 products.\n","- Samsung has a whopping 4,801 products.\n","- Sony offers 780 products.\n","- Target has 2 products.\n","- Verizon has 405 products.\n","- Walmart has 6 products.\n","\n","This list includes all companies, even those with no products, thanks to the way the data was gathered.\n","\n","I analyzed data based on the following filters and transformations:\n","...\n","\n","üßÆ Aggregations: ‚Ä¢ COUNT(products.product_id)\n","\n","üì¶ Groupings: ‚Ä¢ company.company_name''',\n","              response_metadata = { 'token_usage' : {'total_tokens' : 1200 } },\n","              id=8  ) \n","\n","]\n","\n","question = 'what is the first company you listed in your previous response?'\n","\n","test_state['question'] = question\n","test_state['messages_log'] = messages_log\n","\n","result = manage_memory_chat_history(test_state)\n","result\n"]},{"cell_type":"markdown","metadata":{"id":"TlLMbl7oO7jo"},"source":["### generates the answer "]},{"cell_type":"code","execution_count":80,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1745651801887,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"Te4lyaKbp8DZ"},"outputs":[],"source":["## create a function that generates the agent answer based on sql query result\n","\n","def generate_answer(state:State):\n","  \"\"\" generates the AI answer taking into consideration the explanation and the result of the sql query that was executed \"\"\"\n","\n","  system_prompt = \"\"\" You are a decision support consultant helping users become more data-driven.\n","     Your task is to answer the user question based on the following information:\n","\n"," - The sql query result which is the result of a query created for the purpose of answering the question.\n"," - The query explanation is a short explanation of the query making you aware of its limitations and underlying assumptions.\n","\n"," User question:\n"," {question}\n","\n"," SQL query explanation:\n"," {sql_query_explanation}\n","\n"," SQL query result:\n"," {sql_query_result}\n","\n"," Take into account the insights from this explanation in your answer.\n"," Answer in simple terms, conversational, non-technical language. Be concise.\n"," \"\"\"\n","\n","  prompt = ChatPromptTemplate.from_messages([\n","    SystemMessage(content = system_prompt),\n","    MessagesPlaceholder(\"messages_log\")\n","  ]\n","  )\n","\n","  chain = (prompt\n","        | llm\n","        | (lambda output: {'llm_answer': f\"{output.content}\\n\\n{create_explanation(state['sql_query'])}\"})\n","  )\n","\n","  return chain.invoke({ 'messages_log': state['messages_log'],\n","                     'question':state['question'],\n","                     'sql_query_explanation':state['sql_query_explanation'],\n","                     'sql_query_result':state['sql_query_result']}\n","                     ,config = create_config('generate_answer'))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":5576,"status":"ok","timestamp":1745651807466,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"jh8M_xens_rR"},"outputs":[],"source":["# test the function\n","test_state.update(generate_answer(test_state))\n","#test_state"]},{"cell_type":"markdown","metadata":{"id":"WFFhFgT2PDH9"},"source":["### assemble the graph"]},{"cell_type":"code","execution_count":81,"metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1745656995421,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"tWQdCVSjHrKO"},"outputs":[],"source":["# assemble graph\n","\n","from langgraph.graph import StateGraph, START, END\n","from langgraph.checkpoint.memory import MemorySaver\n","\n","graph= StateGraph(State)\n","graph.add_node(\"create_sql_query_or_queries\",create_sql_query_or_queries)\n","graph.add_node(\"execute_sql_query\",execute_sql_query)\n","graph.add_node(\"generate_answer\",generate_answer)\n","graph.add_node(\"manage_memory_chat_history\",manage_memory_chat_history)\n","\n","graph.add_edge(START,\"create_sql_query_or_queries\")\n","graph.add_edge(\"create_sql_query_or_queries\",\"execute_sql_query\")\n","graph.add_edge(\"execute_sql_query\",\"manage_memory_chat_history\")\n","graph.add_edge(\"manage_memory_chat_history\",\"generate_answer\")\n","graph.add_edge(\"generate_answer\",END)\n","\n","memory = MemorySaver()\n","graph = graph.compile(checkpointer=memory)"]},{"cell_type":"markdown","metadata":{"id":"GBxFV-aePGIw"},"source":["### test the agent"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":24556,"status":"ok","timestamp":1745657021519,"user":{"displayName":"Mihnea Dinu","userId":"13042364139523245499"},"user_tz":-180},"id":"XT-hREYWN_Jf","outputId":"181fe769-7581-46c8-be1a-c69a660f34f8"},"outputs":[],"source":["messages_log = [\n","    HumanMessage(content = 'How many companies are there?',id=1),\n","    AIMessage(content = '''üì£ Final Answer:\n","\n","There are 12 unique companies listed in the data. Keep in mind, though, that if there are any variations in how the company names are written (like different spellings or capitalization), it might affect the count slightly.\n","\n","I analyzed data based on the following filters and transformations:\n","\n","üßä Tables: ‚Ä¢ company\n","\n","üßÆ Aggregations: ‚Ä¢ COUNT(DISTINCT company.company_name)''',id=2),\n","\n","    HumanMessage(content = 'What can you tell me about the dataset?',id=3),\n","    AIMessage(content = '''üì£ Final Answer:\n","\n","The dataset provides some interesting insights:\n","\n","1. There are 12 unique companies listed in the dataset.\n","2. On average, these companies have an annual revenue of about $26.3 trillion USD.\n","3. There are 413,898 unique feedback entries, which means a lot of feedback has been collected.\n","4. The average feedback rating is approximately 3.84 out of a possible scale (not specified here).\n","5. There are 8,145 unique products in the dataset.\n","\n","These numbers give a broad overview of the dataset, showing a diverse range of companies, a significant amount of feedback, and a large variety of products. However, it doesn't dive into specifics like industry types, regional data, or detailed company attributes.\n","\n","I analyzed data based on the following filters and transformations:\n","\n","üßä Tables: ‚Ä¢ company ‚Ä¢ feedback ‚Ä¢ products\n","\n","üßÆ Aggregations: ‚Ä¢ COUNT(DISTINCT company.company_name) ‚Ä¢ AVG(company.annual_revenue_usd) ‚Ä¢ COUNT(DISTINCT feedback.feedback_id) ‚Ä¢ AVG(feedback.feedback_rating) ‚Ä¢ COUNT(DISTINCT products.product_id)',id=5),\n","    HumanMessage(content = 'tell me a joke about rum refering to my name''',id=4),\n","   \n","    HumanMessage(content = 'Can you share the average feedback rating per company?',id=5),\n","    AIMessage(content = '''üì£ Final Answer:\n","\n","Sure! Here's the average feedback rating for each company based on the data we have:\n","\n","- Adidas: 4.06\n","- Apple: 3.85\n","- AT&T: 3.66\n","- Cisco: 3.37\n","- Google: 3.56\n","- Microsoft: 3.91\n","- Nike: 3.95\n","- Samsung: 3.87\n","- Sony: 3.83\n","- Target: 3.33\n","- Verizon: 3.84\n","- Walmart: 3.31\n","\n","These numbers represent the average feedback ratings from customers for each company. Keep in mind that this is a straightforward average and doesn't account for things like the number of feedback entries or any unusual ratings that might affect the average.\n","\n","I analyzed data based on the following filters and transformations:\n","...\n","\n","üßÆ Aggregations: ‚Ä¢ AVG(feedback.feedback_rating)\n","\n","üì¶ Groupings: ‚Ä¢ feedback.product_company_name''',id=6),\n","    \n","    HumanMessage(content = 'fine, and how many products each company has?',id=7),\n","    AIMessage(content = '''üì£ Final Answer:\n","\n","Sure! Here's a quick rundown of how many products each company has:\n","\n","- Adidas has 181 products.\n","- Apple offers 1,178 products.\n","- AT&T has 134 products.\n","- Cisco has 9 products.\n","- Google has 459 products.\n","- Microsoft offers 75 products.\n","- Nike has 115 products.\n","- Samsung has a whopping 4,801 products.\n","- Sony offers 780 products.\n","- Target has 2 products.\n","- Verizon has 405 products.\n","- Walmart has 6 products.\n","\n","This list includes all companies, even those with no products, thanks to the way the data was gathered.\n","\n","I analyzed data based on the following filters and transformations:\n","...\n","\n","üßÆ Aggregations: ‚Ä¢ COUNT(products.product_id)\n","\n","üì¶ Groupings: ‚Ä¢ company.company_name''',\n","              response_metadata = { 'token_usage' : {'total_tokens' : 1200 } },\n","              id=8  ) \n","\n","]\n","\n","#messages_log = []\n","\n","question = 'what is the first company you listed in your previous response?'\n","\n","initial_dict = {'objects_documentation':objects_documentation,\n","     'messages_log': messages_log,\n","     'question':question,\n","     'sql_query': [],\n","     'sql_query_result': [],\n","     'sql_query_explanation': [],\n","     'llm_answer': ''\n","     }\n","\n","thread_id = 'abc139'\n","config = { 'configurable' : { 'thread_id':thread_id} }\n","\n","for step in graph.stream(initial_dict, config = config, stream_mode=\"updates\"):\n","  step_name, output = list(step.items())[0]\n","  if step_name == 'create_sql_query_or_queries':\n","    print(f\"‚úÖ SQL queries created:{len(output['sql_query'])}\")\n","  elif step_name == 'execute_sql_query':\n","    print(\"‚öôÔ∏è Analysing results...\")\n","  elif step_name == 'generate_answer':\n","    print(\"\\nüì£ Final Answer:\\n\")\n","    print(output['llm_answer'])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPXPMNTeyikjHOE73oHocjZ","collapsed_sections":["590F0KaCNnLI","aktkTiDQOb-a","3IFkVYMsw5h6","q9yns7F1Ope2","9M8JLe_FOyVS","cGrig_oyFiYs","LOsY-ugvxH2c","TlLMbl7oO7jo","WFFhFgT2PDH9","GBxFV-aePGIw"],"provenance":[]},"interpreter":{"hash":"951c4e1ccc8e7dc066b7b3456b4d29f8a6c8c8949bd81a565897b5da2568416e"},"kernelspec":{"display_name":"Python 3.9.13 ('.venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
