{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc147a51",
   "metadata": {},
   "source": [
    "### Import feedbacks.db file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a5b824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test access to db file: import db tables into data frames and select by the column names\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import uuid\n",
    "\n",
    "engine = create_engine('sqlite:///feedbacks_db.db')\n",
    "inspector = inspect(engine)\n",
    "\n",
    "df_company = pd.read_sql_query('SELECT company_name,annual_revenue_usd FROM company', engine)\n",
    "df_feedback = pd.read_sql_query('SELECT feedback_id,feedback_date,product_id,product_company_name,feedback_text,\"feedback_rating\" FROM feedback', engine)\n",
    "df_products = pd.read_sql_query('SELECT product_id,product_name,product_brand,product_manufacturer,product_company_name,product_price,product_average_rating FROM products', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4008f31",
   "metadata": {},
   "source": [
    "### Instantiate chat model (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8de278ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain, langgraph, langchain_openai, langsmith\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "os.environ['LANGSMITH_API_KEY'] = LANGSMITH_API_KEY\n",
    "os.environ['LANGSMITH_TRACING'] = \"true\"\n",
    "os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "langsmith_project_name = \"db_agent_v1\"\n",
    "os.environ['LANGSMITH_PROJECT'] = langsmith_project_name\n",
    "\n",
    "# Set up LangSmith tracer manually\n",
    "tracer = LangChainTracer(project_name=langsmith_project_name)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o',temperature=0) # Smart & expensive\n",
    "llm_fast = ChatOpenAI(model='gpt-4.1') # Faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530fc53d",
   "metadata": {},
   "source": [
    "### Create config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1b11c69a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_config(run_name: str, is_new_thread_id: bool = False, thread_id: str = None):\n",
    "    \"\"\"\n",
    "    Create a config dictionary for LCEL runnables.\n",
    "    Includes LangSmith run tracing and optional thread_id management.\n",
    "\n",
    "    Args:\n",
    "        run_name (str): Descriptive run name shown in LangSmith.\n",
    "        is_new_thread_id (bool): Whether to generate a new thread_id.\n",
    "        thread_id (str): Optionally provide an existing thread_id to reuse.\n",
    "\n",
    "    Returns:\n",
    "        dict: Config dictionary with callbacks, run_name, and thread_id.\n",
    "\n",
    "    Use it like so (example): \n",
    "        config, thread_id = create_config('create_sql_query_or_queries', True) (start a new thread)\n",
    "        config, _ = create_config('generate_answer', False, thread_id) (re-use same thread)\n",
    "    \"\"\"\n",
    "\n",
    "    time_now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    full_run_name = f\"{run_name} {time_now}\"\n",
    "    if is_new_thread_id or not thread_id:\n",
    "        thread_id = str(uuid.uuid4())\n",
    "\n",
    "    config={'callbacks': [tracer],\n",
    "            'run_name': full_run_name,\n",
    "            'configurable' : { 'thread_id':thread_id }\n",
    "            }\n",
    "\n",
    "    return config,thread_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebaf8f1",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7348f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = None\n",
    "\n",
    "objects_documentation = '''Table company: List of public companies. Granularity is company-name. Column (prefixed with table name):\n",
    "     company.company-name: the name of the public company.\n",
    "     company.annual_revenue_usd: revenue in last 12 months ($).\n",
    "\n",
    "     Table feedback: Feedbacks given by clients to products. Granularity is feedback. Key is feedback_id. Columns (prefixed with table name):\n",
    "     feedback.feedback_id: id of the feedback.\n",
    "     feedback.feedback_date: date of feedback.\n",
    "     feedback.product_id: id of the product the feedback was given for.\n",
    "     feedback.product_company_name: company owning the product.\n",
    "     feedback.feedback_text: the text of the feedback.\n",
    "     feedback.feedback_rating: rating of the feedback from 1 to 5, 5 being the highest score.\n",
    "\n",
    "     Table products: Shows product metadata. Granularity is product. Key is product_id. Columns (prefixed with table name):\n",
    "     products.product_id: id of the product.\n",
    "     products.product_name: name of the product.\n",
    "     products.product_brand: the brand under which the product was presented.\n",
    "     products.product_manufacturer: product manufacturer.\n",
    "     products.product_company_name: company owning the product.\n",
    "     products.product_price: price of the product at crawling time.\n",
    "     products.product_average-rating: average ratings across all feedbacks for the product, at crawling time.\n",
    "\n",
    "     Table company -> column company_name relates to table feedback -> column product_company_name\n",
    "     Table products -> column product_company_name relates to table feedback -> column product_company-name\n",
    "     Table feedback -> column product_id relates to table products -> column product_id'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977899ef",
   "metadata": {},
   "source": [
    "### Define state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d272a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the state of the graph, which includes user's question, AI's answer, query that has been created and its result;\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Sequence\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, RemoveMessage\n",
    "from langchain_core.agents import AgentAction\n",
    "import operator\n",
    "\n",
    "class State(TypedDict):\n",
    " objects_documentation: str\n",
    " messages_log: Sequence[BaseMessage]\n",
    " intermediate_steps: list[AgentAction]\n",
    " current_question: str\n",
    " current_sql_queries: list[dict]\n",
    " llm_answer: BaseMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27d37d",
   "metadata": {},
   "source": [
    "### Create sql query or queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2a830ba6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# create a function that generates the sql query to be executed\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "class OutputAsAQuery(TypedDict):\n",
    "  \"\"\" generated sql query or sql queries if there are multiple \"\"\"\n",
    "  query: Annotated[list[str],\"clean sql query\"]\n",
    "\n",
    "@tool\n",
    "def create_sql_query_or_queries(state:State):\n",
    "  \"\"\" creates sql query/queries to anwser a question based on documentation of tables and columns available \"\"\"\n",
    "\n",
    "  system_prompt = \"\"\"You are a sql expert and an expert data modeler.  \n",
    "\n",
    "  Your task is to create a sql script to answer the user's question. In the sql script, use only these tables and columns you have access to:\n",
    "  {objects_documentation}\n",
    "\n",
    "  User question:\n",
    "  {question}\n",
    "\n",
    "  Answer just with the resulting sql code.\n",
    "\n",
    "  IMPORTANT:\n",
    "    - Return only raw SQL strings in the list.\n",
    "    - DO NOT include comments (like \"-- Query 1\"), labels, or explanations.\n",
    "    - If only one SQL query is needed, just return a list with that one query.\n",
    "    - Do not generate more than 5 queries.\n",
    "\n",
    "  Example output:\n",
    "    [\n",
    "      \"SELECT COUNT(*) FROM feedback;\",\n",
    "      \"SELECT AVG(product_price) FROM products;\"\n",
    "    ]\n",
    "  \"\"\"\n",
    "\n",
    "  prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', system_prompt)]\n",
    "  )\n",
    "\n",
    "  chain = prompt | llm.with_structured_output(OutputAsAQuery)\n",
    "\n",
    "  result = chain.invoke({'objects_documentation':state['objects_documentation'], 'question': state['current_question']})\n",
    "  for q in result['query']:\n",
    "   state['current_sql_queries'].append( {'query': q,\n",
    "                                     'explanation': '', ## add it later\n",
    "                                     'result':'', ## add it later\n",
    "                                     'insight': '', ## add it later\n",
    "                                     'metadata':'' ## add it later\n",
    "                                      } )\n",
    "  \n",
    "  print(f\"✅ SQL queries created:{len(state['current_sql_queries'])}\")\n",
    "  return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "188b45f9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# since gpt-4o allows a maximum completion limit (output context limit) of 4k tokens, I half it to get maximum context size, so 2k. Assuming the entire context is not just the data,\n",
    "# I divide this number by 5 and arrive at a limit of 400 tokens for the result of the sql query.\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "maximum_nr_tokens_sql_query = 200\n",
    "\n",
    "# create a function that counts the tokens from a string\n",
    "def count_tokens(string:str):\n",
    " \"\"\" returns the number of tokens in a text string \"\"\"\n",
    " encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    " num_tokens = len(encoding.encode(string))\n",
    " return num_tokens\n",
    "\n",
    "# create a function that compares the tokens from the sql query result with the maximum token limit, and returns true if the context limit has been exceeded, false otherwise.\n",
    "def check_if_exceed_maximum_context_limit(sql_query_result):\n",
    " \"\"\" compares the tokens from the sql query result with the maximum token limit, and returns true if the context limit has been exceeded, false otherwise \"\"\"\n",
    " tokens_sql_query_result = count_tokens(sql_query_result)\n",
    " if tokens_sql_query_result > maximum_nr_tokens_sql_query:\n",
    "  return True\n",
    " else:\n",
    "  return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0992424",
   "metadata": {},
   "source": [
    "### Create query analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2d949731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryAnalysis(TypedDict):\n",
    "    ''' complete analysis of a sql query, including its explanation, limitation and insight '''\n",
    "    explanation: str\n",
    "    limitation: str\n",
    "    insight: str\n",
    "\n",
    "def create_query_analysis(sql_query:str, sql_query_result:str):\n",
    "   ''' creates: explanation - a concise explanation of what the sql query does.\n",
    "                limitation - a concise explanation of the sql query by pointing out its limitations.\n",
    "                insight - insight from the result of the sql query.\n",
    "   '''\n",
    "   system_prompt = \"\"\"\n",
    "   You are an expert data analyst.\n",
    "\n",
    "   You are provided with the following SQL query:\n",
    "   {sql_query}.\n",
    "\n",
    "   Which yielded the following result:\n",
    "   {sql_query_result}.\n",
    "\n",
    "   Provide a structured analysis with three components:\n",
    "\n",
    "   Step 1: Explanation: A concise description of what the query outputs, in one short phrase. \n",
    "                   Do not include introductory words like \"The query\" or \"It outputs.\"\n",
    "\n",
    "   Step 2: Limitation: Inherent limitations or assumptions of the query based strictly on its structure and logic.\n",
    "                  Focus on:\n",
    "                  - How LIMIT, ORDER BY, GROUP BY, or JOINs may introduce assumptions\n",
    "                  - How filtering or aggregation logic may bias the output\n",
    "                  - Situations where the query might **return incomplete or misleading results due to logic only**\n",
    "                  - Cases where ORDER BY combined with LIMIT might exclude other rows with equal values (ties)\n",
    "\n",
    "                  Only describe things that follow **logically from the query**, not from the dataset itself.\n",
    "\n",
    "                  🚫 Do NOT mention:\n",
    "                  - speculate on what the user is trying to analyze\n",
    "                  - suggest what insights are missing\n",
    "                  - mention field names being correct or incorrect\n",
    "                  - mention data types, nulls, formatting, spelling, or schema correctness\n",
    "                  - mention what other attributes, columns, filters, or relationships \"could have\" been used\n",
    "                  - assume anything about the intent behind the query\n",
    "\n",
    "                  If the query has no structural limitations or assumptions, respond with exactly \"No comments for the query\".\n",
    "\n",
    "                  Respond in 1 to 3 concise sentences, or with the exact phrase above.\n",
    "   \n",
    "   Step 3: Insight: Key findings from the results, stating facts directly without technical terms.\n",
    "               - Include the limitations discovered in step 2, as long as it's different than \"No comments for the query\".\n",
    "               - Do not mention your subjective assessment over the results.\n",
    "               - Avoid technical terms like \"data\",\"dataset\",\"table\",\"list\",\"provided information\",\"query\" etc.\n",
    "   \"\"\"\n",
    "\n",
    "   prompt = ChatPromptTemplate.from_messages(('system',system_prompt))\n",
    "   chain = prompt | llm_fast.with_structured_output(QueryAnalysis)\n",
    "   return chain.invoke({'sql_query':sql_query,\n",
    "                        'sql_query_result':sql_query_result})   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc11ef",
   "metadata": {},
   "source": [
    "### Create query metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "231961b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "from sqlglot import parse_one, exp\n",
    "\n",
    "def extract_metadata_from_sql_query(sql_query):\n",
    "   # returns a dictionary with parsed names of tables and columns used in filters, aggregations and groupings \n",
    "   \n",
    " ast = parse_one(sql_query)\n",
    "\n",
    " sql_query_metadata = {\n",
    "    \"tables\": [],\n",
    "    \"filters\": [],\n",
    "    \"aggregations\": [],\n",
    "    \"groupings\": []\n",
    " }\n",
    "\n",
    " # extract tables\n",
    " table_generator = ast.find_all(sqlglot.expressions.Table)\n",
    " for items in table_generator:\n",
    "    sql_query_metadata['tables'].append(items.sql())\n",
    " # remove dups\n",
    " sql_query_metadata['tables'] = list(dict.fromkeys(sql_query_metadata['tables']))\n",
    "\n",
    " # extract filters\n",
    " where_conditions = ast.find_all(sqlglot.expressions.Where)\n",
    " for item in where_conditions:\n",
    "  sql_query_metadata['filters'].append(item.this.sql())\n",
    "  # remove dups\n",
    " sql_query_metadata['filters'] = list(dict.fromkeys(sql_query_metadata['filters']))\n",
    "\n",
    " # extract aggregate functions\n",
    " funcs = ast.find_all(sqlglot.expressions.AggFunc)\n",
    " for item in funcs:\n",
    "  sql_query_metadata['aggregations'].append(item.sql())\n",
    " # remove dups\n",
    " sql_query_metadata['aggregations'] = list(dict.fromkeys(sql_query_metadata['aggregations']))\n",
    "\n",
    " # extract groupings\n",
    " groupings = ast.find_all(sqlglot.expressions.Group)\n",
    " for item in groupings:\n",
    "  groupings_flattened = item.flatten()\n",
    "  for item in groupings_flattened:\n",
    "    sql_query_metadata['groupings'].append(item.sql())\n",
    " # remove dups\n",
    " sql_query_metadata['groupings'] = list(dict.fromkeys(sql_query_metadata['groupings']))\n",
    "\n",
    " return {'tables':sql_query_metadata.get('tables'),\n",
    "         'filters':sql_query_metadata.get('filters'),\n",
    "         'aggregations':sql_query_metadata.get('aggregations'),\n",
    "         'groupings':sql_query_metadata.get('groupings'),\n",
    "          }\n",
    "\n",
    "def format_sql_metadata_explanation(tables:list=None, filters:list=None, aggregations:list=None, groupings:list=None,header :str='') -> str:\n",
    "    # creates a string explanation of the filters, tables, aggregations and groupings used by the query\n",
    "    explanation = header\n",
    "\n",
    "    if tables:\n",
    "        explanation += \"\\n\\n🧊 Tables: • \" + \" • \".join(tables)\n",
    "    if filters:\n",
    "        explanation += \"\\n\\n🔍 Filters applied: • \" + \" • \".join(filters)\n",
    "    if aggregations:\n",
    "        explanation += \"\\n\\n🧮 Aggregations: • \" + \" • \".join(aggregations)\n",
    "    if groupings:\n",
    "        explanation += \"\\n\\n📦 Groupings: • \" + \" • \".join(groupings)\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def create_query_metadata(sql_query: str):\n",
    " \"\"\" creates an explanation for one single query \"\"\"\n",
    "\n",
    " metadata = extract_metadata_from_sql_query(sql_query)\n",
    " return format_sql_metadata_explanation(metadata['tables'],metadata['filters'],metadata['aggregations'],metadata['groupings'])\n",
    "\n",
    "\n",
    "def create_queries_metadata(sql_queries: list[dict]):\n",
    " \"\"\" creates an explanation for multiple queries: used in the generate_answer tool \"\"\"\n",
    "\n",
    " all_tables = []\n",
    " all_filters = []\n",
    " all_aggregations = []\n",
    " all_groupings = []\n",
    "\n",
    " for q in sql_queries: \n",
    "\n",
    "  metadata = extract_metadata_from_sql_query(q['query'])\n",
    "  all_tables.extend(metadata[\"tables\"])\n",
    "  all_filters.extend(metadata[\"filters\"])\n",
    "  all_aggregations.extend(metadata[\"aggregations\"])\n",
    "  all_groupings.extend(metadata[\"groupings\"])\n",
    "  \n",
    "  # include all metadata\n",
    "  #output = format_sql_metadata_explanation(all_tables,all_filters,all_aggregations,all_groupings,header='🔍 Filters applied:')\n",
    "\n",
    "  # include the default min/max feedback filters if feedback table has been used and was not filtered at all\n",
    "  if 'feedback' in all_tables and not any('feedback_date' in item for item in all_filters):\n",
    "     all_filters.append('feedback_date between 11/18/2002 and 09/12/2023')\n",
    "     output = format_sql_metadata_explanation(filters = all_filters,header='')\n",
    "  # include just the filters if there are any\n",
    "  elif all_filters:    \n",
    "     output = format_sql_metadata_explanation(filters = all_filters,header='')\n",
    "  # if no filters were applied, don't include other metadata for the sake of keeping the message simple\n",
    "  else:\n",
    "     output = ''   \n",
    "\n",
    " return output\n",
    "\n",
    "# use it like so:\n",
    "#sql_queries = [ \n",
    "#    {'query':'SELECT COUNT(DISTINCT company.company_name) FROM company;', 'result':''} ,\n",
    "#    {'query':'SELECT COUNT(DISTINCT feedback.feedback_id) FROM feedback;', 'result':''} \n",
    "#    ]\n",
    "#create_queries_metadata(sql_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "54c04c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries = [ \n",
    "    {'query':'SELECT COUNT(DISTINCT company.company_name) FROM company;', 'result':''} ,\n",
    "    {'query':'SELECT COUNT(DISTINCT feedback.feedback_id) FROM feedback;', 'result':''} \n",
    "    ]\n",
    "\n",
    "all_tables = []\n",
    "all_filters = []\n",
    "all_aggregations = []\n",
    "all_groupings = []\n",
    "\n",
    "for q in sql_queries: \n",
    "  metadata = extract_metadata_from_sql_query(q['query'])\n",
    "  all_tables.extend(metadata[\"tables\"])\n",
    "  all_filters.extend(metadata[\"filters\"])\n",
    "  all_aggregations.extend(metadata[\"aggregations\"])\n",
    "  all_groupings.extend(metadata[\"groupings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e5611c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filters.append('feedback_date between 11/18/2002 and 09/12/2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e9664b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feedback_date between 11/18/2002 and 09/12/2023']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d003cf",
   "metadata": {},
   "source": [
    "### Retrieve insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c644c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_retrieve_vector_store():\n",
    " global vector_store  \n",
    " if vector_store is None:\n",
    "    vector_store = InMemoryVectorStore(embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    " return vector_store\n",
    "\n",
    "# use it like so: vector_store = create_or_retrieve_vector_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b5f0462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_explanation(content:str):\n",
    "    ''' from a text with a format of Query Explanation: ... Query Insight: ...  parse just the explanation part '''\n",
    "    match = re.search(r\"Query Explanation:(.*?)Query Insight:\", content, re.DOTALL)\n",
    "    explanation = match.group(1).strip()  # removes leading/trailing whitespace including \\n\n",
    "    return explanation\n",
    "\n",
    "@tool\n",
    "def retrieve_insights(state:State):\n",
    "    ''' Searches the vector store for relevant past query insights with similarity > 0.6,\n",
    "    and appends them to state['current_sql_queries'] '''\n",
    "    print(\"💭 Gathering my thoughts...\")\n",
    "    query = state['current_question']\n",
    "    vector_store = create_or_retrieve_vector_store()\n",
    "    result = vector_store.similarity_search_with_score(query,k=3)\n",
    "    for doc,score in result:\n",
    "     if score >= 0.6:   \n",
    "      state['current_sql_queries'].append( {'query': doc.metadata.get('query'),\n",
    "                                     'explanation': parse_explanation(doc.page_content), \n",
    "                                     'result':doc.metadata.get('result'), \n",
    "                                     'insight': doc.metadata.get('insight'),\n",
    "                                     'metadata':doc.metadata.get('metadata')\n",
    "                                      } )    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d1c989",
   "metadata": {},
   "source": [
    "### Execute sql query and stores result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f766366d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# the function checks if the query output exceeds context window limit and if yes, send the query for refinement\n",
    "\n",
    "from langchain_community.tools import QuerySQLDataBaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from typing import Iterator\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "\n",
    "def execute_sql_query(state:State):\n",
    "  \"\"\" executes the sql query and retrieve the result \"\"\"\n",
    "  \n",
    "  print(\"⚙️ Analysing results...\")\n",
    "  for query_index, q in enumerate(state['current_sql_queries']):\n",
    "     \n",
    "    if state['current_sql_queries'][query_index]['result'] == '':    \n",
    "     sql_query = q['query'] \n",
    "    \n",
    "     # refine the query 3 times if necessary.\n",
    "     for i in range(3):\n",
    "\n",
    "       sql_query_result = QuerySQLDataBaseTool(db=db).invoke(sql_query)\n",
    "\n",
    "       # if the sql query does not exceed output context window return its result\n",
    "       if not check_if_exceed_maximum_context_limit(sql_query_result):\n",
    "         analysis = create_query_analysis(sql_query, sql_query_result)\n",
    "         sql_query_metadata = create_query_metadata(sql_query)   \n",
    "\n",
    "         # Update state\n",
    "         state['current_sql_queries'][query_index]['result'] = sql_query_result\n",
    "         state['current_sql_queries'][query_index]['insight'] = analysis['insight']\n",
    "         state['current_sql_queries'][query_index]['query'] = sql_query\n",
    "         state['current_sql_queries'][query_index]['metadata'] = sql_query_metadata\n",
    "         state['current_sql_queries'][query_index]['explanation'] = analysis['explanation']   \n",
    "\n",
    "         # add the queries to vector store\n",
    "         vector_store = create_or_retrieve_vector_store()\n",
    "         doc = [Document(\n",
    "              id=len(vector_store.store)+1,\n",
    "              page_content=f\"Query Explanation:\\n{analysis['explanation'] }\\n\\Query Insight:{analysis['insight']}\",\n",
    "              metadata={\"query\": sql_query,\n",
    "                        \"result\": sql_query_result,\n",
    "                        \"insight\": analysis['insight'],\n",
    "                        \"metadata\": sql_query_metadata\n",
    "                        })]\n",
    "         vector_store.add_documents(documents=doc)                                                          \n",
    "         break\n",
    "\n",
    "       # if the sql query exceeds output context window and there is more room for iterations, refine the query\n",
    "       else:\n",
    "        print(f\"🔧 Refining query {query_index+1}/{len(state['current_sql_queries'])} as its output its too large...\")\n",
    "        sql_query = refine_sql_query(state['current_question'],sql_query,maximum_nr_tokens_sql_query)['query']\n",
    "\n",
    "       # if there is no more room for sql query iterations and the result still exceeds context window, throw a message\n",
    "     else:\n",
    "        print(f\"⚠️ Query result too large after 3 refinements.\")\n",
    "        state['current_sql_queries'][query_index]['result'] = 'Query result too large after 3 refinements.'\n",
    "        state['current_sql_queries'][query_index]['explanation'] = \"Refinement failed.\"\n",
    "      \n",
    "  return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a7489351",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class OutputAsASingleQuery(TypedDict):\n",
    "  \"\"\" generated sql query \"\"\"\n",
    "  query: Annotated[str,...,\"the generated sql query\"]\n",
    "\n",
    "def refine_sql_query(question: str, sql_query: str, maximum_nr_tokens_sql_query: int):\n",
    " \"\"\" refines the sql query so that its output tokens do not exceed the maximum context limit \"\"\"\n",
    "\n",
    " system_prompt = \"\"\"\n",
    " You are a sql expert an an expert data modeler.\n",
    "\n",
    " You are tying to answer the following question from the user:\n",
    " {question}\n",
    "\n",
    " The following sql query produces an output that exceeds {maximum_nr_tokens_sql_query} tokens:\n",
    " {sql_query}\n",
    "\n",
    " Please optimize this query so that its output stays within the token limit while still providing as much insight as possible to answer the question.\n",
    " Prefer using WHERE or LIMIT clauses to reduce the size of the result.\n",
    " \"\"\"\n",
    " \n",
    " prompt = ChatPromptTemplate.from_messages(\n",
    "   ('system',system_prompt)\n",
    " )\n",
    "\n",
    " chain = (prompt\n",
    "         | llm.with_structured_output(OutputAsASingleQuery)\n",
    " )\n",
    "\n",
    " sql_query = chain.invoke({'question': question,\n",
    "               'sql_query':sql_query,\n",
    "               'maximum_nr_tokens_sql_query':maximum_nr_tokens_sql_query}\n",
    "               )\n",
    " return sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8952f76b",
   "metadata": {},
   "source": [
    "### Generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "65eaed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sql_query_results_for_prompt (sql_queries : list[dict]) -> str:\n",
    "    \n",
    "    formatted_queries = []\n",
    "    for query_index,q in enumerate(sql_queries):\n",
    "        block = f\"Insight {query_index+1}:\\n{q['insight']}\\n\\nRaw Result of insight {query_index+1}:\\n{q['result']}\"\n",
    "        formatted_queries.append(block)\n",
    "    return \"\\n\\n\".join(formatted_queries)\n",
    "\n",
    "# print(format_sql_query_results_for_prompt(test_state['sql_queries']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "17735fb5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "## create a function that generates the agent answer based on sql query result\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "@tool\n",
    "def generate_answer(state:State):\n",
    "  \"\"\" generates the AI answer taking into consideration the explanation and the result of the sql query that was executed \"\"\"\n",
    "\n",
    "  system_prompt = \"\"\" You are a decision support consultant helping users become more data-driven.\n",
    "     Continue the conversation by answering the following question: {question}.\n",
    "\n",
    "     Use both the raw SQL results and the extracted insights below to form your answer: {insights}. Include all details from these insights.\n",
    "\n",
    "     Respond in clear, concise, non-technical language.\n",
    "     \"\"\"\n",
    "\n",
    "  prompt = ChatPromptTemplate.from_messages([\n",
    "      MessagesPlaceholder(\"messages_log\") ,\n",
    "      ('system',system_prompt)            \n",
    "  ] )\n",
    "\n",
    "  llm_answer_chain = prompt | llm \n",
    "  final_answer_chain = { 'llm_answer': llm_answer_chain, 'input_state': RunnablePassthrough() } | RunnableLambda (lambda x: { 'ai_message': AIMessage( content = f\"{x['llm_answer'].content}\\n\\n{create_queries_metadata(x['input_state']['current_sql_queries'])}\", \n",
    "                                                                                                                                                        response_metadata = x['llm_answer'].response_metadata  ) } ) \n",
    "\n",
    "  result = final_answer_chain.invoke({ 'messages_log':state['messages_log'],\n",
    "               'question':state['current_question'],\n",
    "               'insights': format_sql_query_results_for_prompt(state['current_sql_queries']),\n",
    "              'current_sql_queries': state['current_sql_queries'] })\n",
    "  \n",
    "  ai_msg = result['ai_message']\n",
    "\n",
    "  explanation_token_count = llm.get_num_tokens(create_queries_metadata(state['current_sql_queries']))\n",
    "  ai_msg.response_metadata['token_usage']['total_tokens'] += explanation_token_count\n",
    "\n",
    "  state['llm_answer'] = ai_msg\n",
    "  state['messages_log'].append(HumanMessage(state['current_question']))\n",
    "  state['messages_log'].append(ai_msg)\n",
    "\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68cae6",
   "metadata": {},
   "source": [
    "### Manage memory and chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6f942bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_memory_chat_history(state:State):\n",
    "    \"\"\" Manages the chat history so that it does not become too large in terms of output tokens.\n",
    "    Specifically, it checks if the chat history is larger than 1000 tokens. If yes, keep just the last 4 pairs of human prompts and AI responses, and summarize the older messages.\n",
    "    Additionally, check if the logs of sql queries is larger than 20 entries. If yes, delete the older records. \"\"\"           \n",
    "\n",
    "    tokens_chat_history = state['messages_log'][-1].response_metadata.get('token_usage', {}).get('total_tokens', 0) if state['messages_log'] else 0    \n",
    "\n",
    "    if tokens_chat_history >= 1000 and len(state['messages_log']) > 4:\n",
    "        message_history_to_summarize = [msg.content for msg in state['messages_log'][:-4]]\n",
    "        prompt = ChatPromptTemplate.from_messages( [('user', 'Distill the below chat messages into a single summary paragraph.The summary paragraph should have maximum 400 tokens.Include as many specific details as you can.Chat messages:{message_history_to_summarize}') ])\n",
    "        runnable = prompt | llm_fast # use the cheap model\n",
    "        chat_history_summary = runnable.invoke({'message_history_to_summarize':message_history_to_summarize})\n",
    "        last_4_messages = state['messages_log'][-4:]\n",
    "        state['messages_log'] = [chat_history_summary] +[*last_4_messages]\n",
    "    else:\n",
    "        state['messages_log'] = state['messages_log']\n",
    "\n",
    "    # Truncate SQL logs to the most recent 20\n",
    "    #if len(state['log_sql_queries']) > 20:\n",
    "    #    state['log_sql_queries']= state['log_sql_queries'][-20:]    \n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e8d9d",
   "metadata": {},
   "source": [
    "### Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "72539d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools =[retrieve_insights,create_sql_query_or_queries,generate_answer]\n",
    "\n",
    "def get_next_tool(state:State):\n",
    "  ''' creates a list of actions taken by the agent from the intermediate steps '''  \n",
    "  nr_executions_retrieve_insights = 0\n",
    "  nr_executions_create_sql_query_or_queries = 0\n",
    "  for index,action in enumerate(state['intermediate_steps']):\n",
    "      \n",
    "    if action.tool == 'retrieve_insights' and action.log == 'tool ran successfully':\n",
    "      nr_executions_retrieve_insights +=1\n",
    "\n",
    "    if action.tool == 'create_sql_query_or_queries' and action.log == 'tool ran successfully':\n",
    "      nr_executions_create_sql_query_or_queries +=1\n",
    "\n",
    "  if nr_executions_retrieve_insights == nr_executions_create_sql_query_or_queries == 1:\n",
    "    next_tool = 'generate_answer'\n",
    "  elif nr_executions_retrieve_insights == 0 and nr_executions_create_sql_query_or_queries == 0:\n",
    "    next_tool = 'retrieve_insights'\n",
    "  elif nr_executions_retrieve_insights > 0 and nr_executions_create_sql_query_or_queries == 0:\n",
    "    next_tool = 'create_sql_query_or_queries'  \n",
    "\n",
    "  return next_tool\n",
    "\n",
    "def extract_msg_content_from_history(messages_log:list):\n",
    " ''' from a list of base messages, extract just the content '''\n",
    " content = []\n",
    " for msg in messages_log:\n",
    "     content.append(msg.content)\n",
    " return \"\\n\".join(content)\n",
    "\n",
    "# use it like so: extract_msg_content_from_history(test_state['messages_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "24098660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator(state:State):\n",
    "  ''' Function that decides which tools to use '''\n",
    "\n",
    "  # if all tools for retrieving insights have been used, go directly to answer.\n",
    "  next_tool = get_next_tool(state)\n",
    "  if next_tool == 'generate_answer':\n",
    "     action = AgentAction(tool='generate_answer', tool_input='', log='')\n",
    "     state['intermediate_steps'].append(action)\n",
    "     return state\n",
    "\n",
    "  else:\n",
    "    system_prompt = f\"\"\"You are a decision support consultant helping users make data-driven decisions.\n",
    "\n",
    "    Your task is to continue the conversation by answering the following question: {{question}}.\n",
    "\n",
    "    Conversation history:\n",
    "    {{messages_log}}.\n",
    "  \n",
    "    You have access to a database available to you with the following schema: {{objects_documentation}}.\n",
    "\n",
    "    Current insights: \"{{insights}}\".\n",
    "  \n",
    "    Decision rules:\n",
    " \n",
    "    Step 1. If current question was already answered in the conversation history, or current insights are sufficient to answer the question, return generate_answer tool.      \n",
    "\n",
    "    Step 2. If current insights are not sufficient to answer the question, return {next_tool} tool.          \n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "      [('system', system_prompt)]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_fast.bind_tools(tools) \n",
    "    result = chain.invoke({'messages_log':extract_msg_content_from_history(state['messages_log']),\n",
    "                         'question': state['current_question'], \n",
    "                         'objects_documentation':state['objects_documentation'],\n",
    "                         'insights': format_sql_query_results_for_prompt(state['current_sql_queries'])\n",
    "                         #'next_tool':get_next_tool(state)\n",
    "                         })\n",
    "\n",
    "    tool_name = result.tool_calls[0][\"name\"]\n",
    "\n",
    "    action = AgentAction( tool=tool_name, tool_input='', log = '' )\n",
    "    state['intermediate_steps'].append(action)  \n",
    "    return state     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce9f3c",
   "metadata": {},
   "source": [
    "### Run control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2a697fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the nodes\n",
    "\n",
    "def run_control_flow(state:State):\n",
    "    ''' Based on the last tool name stored in intermediate_steps (generated by the orchestrator), it executes the next node that will trigger the control flow '''\n",
    "    \n",
    "    # get the next tool to execute by looking in the last tool_name in the intermediate steps\n",
    "    tool_name = state['intermediate_steps'][-1].tool\n",
    "    \n",
    "    # control flow 1: retrieve insights from previous run queries\n",
    "    if tool_name == 'retrieve_insights':\n",
    "      state = retrieve_insights.invoke({'state':state})   \n",
    "      # log the tool call\n",
    "      action = AgentAction(tool=tool_name, tool_input='',log='tool ran successfully')\n",
    "      state['intermediate_steps'].append(action)\n",
    "\n",
    "    # control flow 2: generate new insights by creating & executing new queries\n",
    "    elif tool_name == 'create_sql_query_or_queries':\n",
    "      state = create_sql_query_or_queries.invoke({'state':state})\n",
    "      execute_sql_query(state)\n",
    "      # log the tool call\n",
    "      action = AgentAction(tool=tool_name, tool_input='',log='tool ran successfully')\n",
    "      state['intermediate_steps'].append(action)\n",
    "\n",
    "    # control flow 3: generate answer & manage chat history.\n",
    "    elif tool_name == 'generate_answer':  \n",
    "      state = generate_answer.invoke({'state':state}) \n",
    "      manage_memory_chat_history(state) \n",
    "      # log the tool call\n",
    "      action = AgentAction(tool=tool_name, tool_input='',log='tool ran successfully')\n",
    "      state['intermediate_steps'].append(action)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7ce8d",
   "metadata": {},
   "source": [
    "### Assemble graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "23aa439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble graph\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# function to reset the state current queries (to add in the start of graph execution)\n",
    "def reset_state(state:State):\n",
    "    state['current_sql_queries'] = []\n",
    "    state['intermediate_steps'] = []\n",
    "    state['llm_answer'] = AIMessage(content='')\n",
    "    state['objects_documentation'] = \"\"\"\n",
    "     Table company: List of public companies. Granularity is company-name. Column (prefixed with table name):\n",
    "     company.company-name: the name of the public company.\n",
    "     company.annual_revenue_usd: revenue in last 12 months ($).\n",
    "\n",
    "     Table feedback: Feedbacks given by clients to products. Granularity is feedback. Key is feedback_id. Columns (prefixed with table name):\n",
    "     feedback.feedback_id: id of the feedback.\n",
    "     feedback.feedback_date: date of feedback.\n",
    "     feedback.product_id: id of the product the feedback was given for.\n",
    "     feedback.product_company_name: company owning the product.\n",
    "     feedback.feedback_text: the text of the feedback.\n",
    "     feedback.feedback_rating: rating of the feedback from 1 to 5, 5 being the highest score.\n",
    "\n",
    "     Table products: Shows product metadata. Granularity is product. Key is product_id. Columns (prefixed with table name):\n",
    "     products.product_id: id of the product.\n",
    "     products.product_name: name of the product.\n",
    "     products.product_brand: the brand under which the product was presented.\n",
    "     products.product_manufacturer: product manufacturer.\n",
    "     products.product_company_name: company owning the product.\n",
    "     products.product_price: price of the product at crawling time.\n",
    "     products.product_average-rating: average ratings across all feedbacks for the product, at crawling time.\n",
    "\n",
    "     Table company -> column company_name relates to table feedback -> column product_company_name\n",
    "     Table products -> column product_company_name relates to table feedback -> column product_company-name\n",
    "     Table feedback -> column product_id relates to table products -> column product_id\n",
    "     \"\"\"\n",
    "    return state\n",
    "\n",
    "def router(state:State):\n",
    "    # returns the tool name to use\n",
    "    return state['intermediate_steps'][-1].tool\n",
    "\n",
    "graph= StateGraph(State)\n",
    "graph.add_node(\"reset_state\",reset_state)\n",
    "graph.add_node(\"orchestrator\",orchestrator)\n",
    "\n",
    "# here you add the node corresponding to the first tool of each control flow, as the subsequent tools are run by the run_control_flow node\n",
    "graph.add_node(\"retrieve_insights\",run_control_flow)\n",
    "graph.add_node(\"create_sql_query_or_queries\",run_control_flow)\n",
    "graph.add_node(\"generate_answer\",run_control_flow)\n",
    "\n",
    "# starting the agent\n",
    "graph.add_edge(START,\"reset_state\")\n",
    "graph.add_edge(\"reset_state\",\"orchestrator\")\n",
    "graph.add_conditional_edges(source='orchestrator',path=router)\n",
    "\n",
    "# here you add a link from each the control flow node back to the orchestator - except for the generate_answer node.\n",
    "graph.add_edge(\"retrieve_insights\",\"orchestrator\")\n",
    "graph.add_edge(\"create_sql_query_or_queries\",\"orchestrator\")\n",
    "\n",
    "# last control flow is generate_answer\n",
    "graph.add_edge(\"generate_answer\",END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fcd929",
   "metadata": {},
   "source": [
    "\n",
    "### test the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "905d7d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💭 Gathering my thoughts...\n",
      "✅ SQL queries created:1\n",
      "⚙️ Analysing results...\n",
      "There are 6,932 unique products that have received a rating of 5.\n",
      "\n",
      "I analyzed data based on the following filters and transformations:\n",
      "\n",
      "🧊 Tables: • feedback • products\n",
      "\n",
      "🔍 Filters: • feedback.feedback_rating = 5\n",
      "\n",
      "🧮 Aggregations: • COUNT(DISTINCT products.product_id)\n"
     ]
    }
   ],
   "source": [
    "# Start a new conversation\n",
    "\n",
    "question = 'How many products have a rating of 5?'\n",
    "messages_log = []\n",
    "\n",
    "initial_dict = {'objects_documentation':objects_documentation,\n",
    "     'messages_log': messages_log,\n",
    "     'intermediate_steps':[],\n",
    "     'current_question':question,\n",
    "     'current_sql_queries': [],\n",
    "     'llm_answer': AIMessage(content='')\n",
    "     }\n",
    "\n",
    "vector_store = None  # reset vector store\n",
    "config, thread_id = create_config('Run Agent',True)\n",
    "\n",
    "result = graph.invoke(initial_dict, config = config)\n",
    "print(result['llm_answer'].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa25680",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in graph.stream(initial_dict, config = config, stream_mode=\"updates\"):\n",
    " step_name, output = list(step.items())[0]\n",
    " if step_name == 'create_sql_query_or_queries':\n",
    "   print(f\"✅ SQL queries created:{len(output['current_sql_queries'])}\")\n",
    " elif step_name == 'execute_sql_query':\n",
    "   print(\"⚙️ Analysing results...\")\n",
    " elif step_name == 'generate_answer':\n",
    "   print(\"\\n📣 Final Answer:\\n\")\n",
    "   print(output['llm_answer'].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0913f62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6,932 unique products that have received a perfect rating of 5. This means that these products have been highly rated by customers, indicating a high level of satisfaction with their quality or performance. If you're looking for top-rated products, these might be a good place to start.\n",
      "\n",
      "I analyzed data based on the following filters and transformations:\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation\n",
    "config, _ = create_config('Run Agent',False,thread_id)\n",
    "result = graph.invoke({\n",
    "    'current_question': 'How many products have a rating of 5?'\n",
    "}, config=config)\n",
    "\n",
    "print(result['llm_answer'].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "518f23b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📣 Final Answer:\n",
      "\n",
      "Based on the data, there are 1,028 products that have a rating of 5. This means that these products have received the highest possible rating from customers, indicating a high level of satisfaction.\n",
      "\n",
      "I analyzed data based on the following filters and transformations:\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation\n",
    "\n",
    "config, _ = create_config('Run Agent',False,thread_id)\n",
    "if __name__ == \"__main__\":\n",
    " for step in graph.stream(initial_dict, config = config, stream_mode=\"updates\"):\n",
    "   step_name, output = list(step.items())[0]\n",
    "   if step_name == 'create_sql_query_or_queries':\n",
    "    print(f\"✅ SQL queries created:{len(output['current_sql_queries'])}\")\n",
    "   elif step_name == 'execute_sql_query':\n",
    "    print(\"⚙️ Analysing results...\")\n",
    "   elif step_name == 'generate_answer':\n",
    "    print(\"\\n📣 Final Answer:\\n\")\n",
    "    print(output['llm_answer'].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ffa2c",
   "metadata": {},
   "source": [
    "### Testing Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b21e19",
   "metadata": {},
   "source": [
    "### test orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c752b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objects_documentation': 'Table company: List of public companies. Granularity is company-name. Column (prefixed with table name):\\n     company.company-name: the name of the public company.\\n     company.annual_revenue_usd: revenue in last 12 months ($).\\n\\n     Table feedback: Feedbacks given by clients to products. Granularity is feedback. Key is feedback_id. Columns (prefixed with table name):\\n     feedback.feedback_id: id of the feedback.\\n     feedback.feedback_date: date of feedback.\\n     feedback.product_id: id of the product the feedback was given for.\\n     feedback.product_company_name: company owning the product.\\n     feedback.feedback_text: the text of the feedback.\\n     feedback.feedback_rating: rating of the feedback from 1 to 5, 5 being the highest score.\\n\\n     Table products: Shows product metadata. Granularity is product. Key is product_id. Columns (prefixed with table name):\\n     products.product_id: id of the product.\\n     products.product_name: name of the product.\\n     products.product_brand: the brand under which the product was presented.\\n     products.product_manufacturer: product manufacturer.\\n     products.product_company_name: company owning the product.\\n     products.product_price: price of the product at crawling time.\\n     products.product_average-rating: average ratings across all feedbacks for the product, at crawling time.\\n\\n     Table company -> column company_name relates to table feedback -> column product_company_name\\n     Table products -> column product_company_name relates to table feedback -> column product_company-name\\n     Table feedback -> column product_id relates to table products -> column product_id',\n",
       " 'messages_log': [],\n",
       " 'intermediate_steps': [AgentAction(tool='retrieve_insights', tool_input='', log='')],\n",
       " 'current_question': 'What is the firm with the most feedback entries?',\n",
       " 'current_sql_queries': [],\n",
       " 'llm_answer': AIMessage(content='', additional_kwargs={}, response_metadata={})}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = None  # reset vector store\n",
    "question = 'What is the firm with the most feedback entries?'\n",
    "test_state = {\n",
    "'objects_documentation':objects_documentation,\n",
    "'messages_log':[],\n",
    "'intermediate_steps' : [],\n",
    "'current_question':question,\n",
    "'current_sql_queries': [],\n",
    "'llm_answer': AIMessage(content='')\n",
    "}\n",
    "\n",
    "orchestrator(test_state)\n",
    "#test_state = run_control_flow(test_state) # retrieve insights\n",
    "#orchestrator(test_state)\n",
    "#test_state = run_control_flow(test_state) # create sql query + execute sql query\n",
    "#orchestrator(test_state)\n",
    "#test_state = run_control_flow(test_state) # generate answer + manage memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ff1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator(test_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "67585d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue the conversation\n",
    "test_state['current_question'] = 'How many feedback entries does Samsung have?'\n",
    "test_state['intermediate_steps'] = []\n",
    "test_state['current_sql_queries'] = []\n",
    "test_state['llm_answer'] = AIMessage(content='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aa4ae4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state = run_control_flow(test_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11da2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the orchestrator\n",
    "\n",
    "vector_store = None  # reset vector store\n",
    "question = 'How many feedback entries does Samsung have?'\n",
    "test_state = {\n",
    "'objects_documentation':objects_documentation,\n",
    "'messages_log':[ HumanMessage(content='What is the firm with the most feedback entries?'),\n",
    "                 AIMessage(content='''The firm with the most feedback entries is Samsung, with a total of 280,625 feedback entries. However, it's important to note that while Samsung is highlighted as having the highest number, there might be other companies with the same number of feedback entries that are not mentioned in the data provided.\n",
    "\n",
    "I analyzed data based on the following filters and transformations:\n",
    "\n",
    "🧊 Tables: • feedback\n",
    "\n",
    "🧮 Aggregations: • COUNT(feedback.feedback_id)\n",
    "\n",
    "📦 Groupings: • feedback.product_company_name''')],\n",
    "'intermediate_steps' : [],\n",
    "'current_question':question,\n",
    "'current_sql_queries': [],\n",
    "'llm_answer': AIMessage(content='')\n",
    "}\n",
    "\n",
    "orchestrator(test_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1580b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = None  # reset vector store\n",
    "question = 'What is the firm with the most feedback entries?'\n",
    "test_state = {\n",
    "'objects_documentation':objects_documentation,\n",
    "'messages_log':[],\n",
    "'intermediate_steps' : [],\n",
    "'current_question':question,\n",
    "'current_sql_queries': [],\n",
    "'llm_answer': AIMessage(content='')\n",
    "}\n",
    "orchestrator(test_state)\n",
    "test_state = run_control_flow(test_state) # retrieve insights\n",
    "orchestrator(test_state)\n",
    "test_state = run_control_flow(test_state) # create sql query + execute sql query\n",
    "orchestrator(test_state)\n",
    "test_state = run_control_flow(test_state) # generate answer + manage memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a433428",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_control_flow(test_state)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "951c4e1ccc8e7dc066b7b3456b4d29f8a6c8c8949bd81a565897b5da2568416e"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
